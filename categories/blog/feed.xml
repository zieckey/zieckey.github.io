<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on CodeG Blog</title>
    <link>http://blog.codeg.cn/categories/blog/</link>
    <description>Recent content in Blog on CodeG Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <copyright>Copyright (c) 2015. All rights reserved.</copyright>
    <lastBuildDate>Sun, 29 May 2016 13:14:00 +0000</lastBuildDate>
    <atom:link href="http://blog.codeg.cn/categories/blog/feed/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>发布一个Golang版本的INI解析器</title>
      <link>http://blog.codeg.cn/post/blog/2016-05-29-a-new-ini-parser-for-golang/</link>
      <pubDate>Sun, 29 May 2016 13:14:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/post/blog/2016-05-29-a-new-ini-parser-for-golang/</guid>
      <description>

&lt;h2 id=&#34;goini:8fa3c65ec3a305344ff164eb6635eadc&#34;&gt;goini&lt;/h2&gt;

&lt;p&gt;这是一个为Golang开发的读取INI格式文件的库，它还能读取类似于INI格式的key/value对数据。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;goini&lt;/code&gt; 的设计目标是简单、灵活、高效，有如下特性：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;支持标准INI格式&lt;/li&gt;
&lt;li&gt;支持节&lt;/li&gt;
&lt;li&gt;支持从本地磁盘中读取INI文件&lt;/li&gt;
&lt;li&gt;支持从内存数据中读取INI数据&lt;/li&gt;
&lt;li&gt;支持解析形如INI格式的key/value对数据，分隔符可以自定义&lt;/li&gt;
&lt;li&gt;支持UTF8编码&lt;/li&gt;
&lt;li&gt;支持注释符 &lt;code&gt;;&lt;/code&gt; or &lt;code&gt;#&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;支持级联继承&lt;/li&gt;
&lt;li&gt;仅仅只依赖Golang标准库&lt;/li&gt;
&lt;li&gt;测试用户100%覆盖&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;使用时导入:8fa3c65ec3a305344ff164eb6635eadc&#34;&gt;使用时导入&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;import github.com/zieckey/goini
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;用法示例:8fa3c65ec3a305344ff164eb6635eadc&#34;&gt;用法示例&lt;/h2&gt;

&lt;h3 id=&#34;示例1-解析ini文件:8fa3c65ec3a305344ff164eb6635eadc&#34;&gt;示例1 : 解析INI文件&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import github.com/zieckey/goini

ini := goini.New()
err := ini.ParseFile(filename)
if err != nil {
	fmt.Printf(&amp;quot;parse INI file %v failed : %v\n&amp;quot;, filename, err.Error())
	return
}

v, ok := ini.Get(&amp;quot;the-key&amp;quot;)
//...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;示例2-解析内存中形如ini格式的数据:8fa3c65ec3a305344ff164eb6635eadc&#34;&gt;示例2 ： 解析内存中形如INI格式的数据&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;raw := []byte(&amp;quot;a:av||b:bv||c:cv||||d:dv||||||&amp;quot;)
ini := goini.New()
err := ini.Parse(raw, &amp;quot;||&amp;quot;, &amp;quot;:&amp;quot;)
if err != nil {
    fmt.Printf(&amp;quot;parse INI memory data failed : %v\n&amp;quot;, err.Error())
    return
}

key := &amp;quot;a&amp;quot;
v, ok := ini.Get(key)
if ok {
    fmt.Printf(&amp;quot;The value of %v is [%v]\n&amp;quot;, key, v) // Output : The value of a is [av]
}

key = &amp;quot;c&amp;quot;
v, ok = ini.Get(key)
if ok {
    fmt.Printf(&amp;quot;The value of %v is [%v]\n&amp;quot;, key, v) // Output : The value of c is [cv]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;示例3-解析级联继承ini文件:8fa3c65ec3a305344ff164eb6635eadc&#34;&gt;示例3 : 解析级联继承INI文件&lt;/h3&gt;

&lt;p&gt;假设我们有一个项目，该项目会部署到多个不同的生产环境中，每一个生产环境的配置都不尽相同，一般情况下，就得为每一个环境分别管理其各自的配置。
为了简化配置，我们抽取各个生产环境中配置的公共部分形成一个 &lt;code&gt;common.ini&lt;/code&gt;, 然后让每个生产环境的配置从这个INI配置文件继承，
这样就可以大大简化配置文件的维护工作。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;common.ini&lt;/code&gt; 举例如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;product=common
combo=common
debug=0

version=0.0.0.0
encoding=0

[sss]
a = aval
b = bval
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;项目 &lt;code&gt;project1.ini&lt;/code&gt; 从 &lt;code&gt;common.ini&lt;/code&gt; 继承而来，如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;inherited_from=common.ini

;the following config will override the values inherited from common.ini
product=project1
combo=test
debug=1

local=0
mid=c4ca4238a0b923820dcc509a6f75849b

[sss]
a = project1-aval
c = project1-cval
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个说话，我们使用 &lt;code&gt;goini.LoadInheritedINI(&amp;quot;project1.ini&amp;quot;)&lt;/code&gt; 来解析这个配置文件，其效果相当下面的INI配置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;product=project1
combo=test
debug=1

local=0
mid=c4ca4238a0b923820dcc509a6f75849b

version=0.0.0.0
encoding=0

[sss]
a = project1-aval
c = project1-cval
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考:8fa3c65ec3a305344ff164eb6635eadc&#34;&gt;参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/zieckey/goini&#34;&gt;项目源码 https://github.com/zieckey/goini&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Trafik源代码阅读</title>
      <link>http://blog.codeg.cn/post/blog/2016-05-26-trafik-source-code-reading/</link>
      <pubDate>Thu, 26 May 2016 07:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/post/blog/2016-05-26-trafik-source-code-reading/</guid>
      <description>

&lt;h2 id=&#34;trafik介绍:34b0e58d062ee9acee54f0313b094782&#34;&gt;Trafik介绍&lt;/h2&gt;

&lt;p&gt;其&lt;a href=&#34;https://docs.traefik.io/&#34;&gt;官网&lt;/a&gt;是这么介绍的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Træfɪk is a modern HTTP reverse proxy and load balancer made to deploy microservices with ease. 
It supports several backends (Docker, Swarm, Mesos/Marathon, Consul, Etcd, Zookeeper, BoltDB, Rest API, file...) 
to manage its configuration automatically and dynamically.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;翻译过来就是：Træfɪk是一个现代的HTTP反向代理和易用的微服务负载平衡器，支持多种后端服务，
例如 Docker、 Swarm、 Mesos/Marathon、 Kubernetes、 Consul、 Etcd、 Zookeeper、 BoltDB、 Rest API、 文件 等等，
可以自动地动态管理和加载各种配置。&lt;/p&gt;

&lt;p&gt;特点如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;快速，benchmark显示，能够达到nginx的85%的性能&lt;/li&gt;
&lt;li&gt;没有依赖地狱，得益于Golang的特性，单个二进制文件就能运行&lt;/li&gt;
&lt;li&gt;Rest API&lt;/li&gt;
&lt;li&gt;监视后端，能够自动监听后端配置的变化。&lt;/li&gt;
&lt;li&gt;配置的热重加载，无需重新启动进程或服务器&lt;/li&gt;
&lt;li&gt;优雅地关闭Http连接&lt;/li&gt;
&lt;li&gt;后端的断路器Circuit breaker&lt;/li&gt;
&lt;li&gt;Round Robin rebalancer 负载平衡&lt;/li&gt;
&lt;li&gt;Rest测量&lt;/li&gt;
&lt;li&gt;包括小的官方docker&lt;/li&gt;
&lt;li&gt;SSL后端支持&lt;/li&gt;
&lt;li&gt;SSL前端支持&lt;/li&gt;
&lt;li&gt;干净的AngularJS Web UI&lt;/li&gt;
&lt;li&gt;支持Websocket&lt;/li&gt;
&lt;li&gt;支持Http/2&lt;/li&gt;
&lt;li&gt;如果网络错误重试请求&lt;/li&gt;
&lt;li&gt;自动Https支持(Let’s Encrypt)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;用法:34b0e58d062ee9acee54f0313b094782&#34;&gt;用法&lt;/h2&gt;

&lt;p&gt;最简单的用法当然是做一个HTTP反向代理用。&lt;/p&gt;

&lt;p&gt;假设我们有一个HTTP服务 &lt;code&gt;http://10.16.28.17:8091/echo&lt;/code&gt;, 我们用Trafik做为反向代理的配置 &lt;code&gt;trafik.toml&lt;/code&gt; 如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;logLevel = &amp;quot;DEBUG&amp;quot;

defaultEntryPoints = [&amp;quot;http&amp;quot;]

[entryPoints]
  [entryPoints.http]
  address = &amp;quot;:8080&amp;quot;

[file]
  [backends]
    [backends.httpecho]
      [backends.httpecho.servers.server1]
        url = &amp;quot;http://10.16.28.17:8091&amp;quot;
        weight = 1
  [frontends]
    [frontends.fe1]
    backend = &amp;quot;httpecho&amp;quot;
      [frontends.fe1.routes.rule1]
      rule = &amp;quot;Path:/echo&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参考Trafik官方文档说明，我们这个配置解释如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将Trafik的日志级别 &lt;code&gt;logLevel&lt;/code&gt; 定义为 &lt;code&gt;DEBUG&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;默认的接入点 &lt;code&gt;defaultEntryPoints&lt;/code&gt; 定义为 &lt;code&gt;http&lt;/code&gt;，并且其端口为 &lt;code&gt;8080&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;然后在 &lt;code&gt;[file]&lt;/code&gt; 段定义 &lt;code&gt;backends&lt;/code&gt; 和 &lt;code&gt;frontends&lt;/code&gt;， 也就是Trafik的路由转发规则&lt;/li&gt;
&lt;li&gt;&lt;code&gt;backends&lt;/code&gt;段定义了一个后端服务，URL地址和权重都设置好了。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frontends&lt;/code&gt;段定义转发规则，即将URL路径为 /echo 的请求转发到合适的 &lt;code&gt;backend&lt;/code&gt; 上。&lt;/li&gt;
&lt;li&gt;然后我们可以用 curl 来测试转发是否正常： &lt;code&gt;curl http://localhost:8080/echo -d xxxxxx&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;源码阅读:34b0e58d062ee9acee54f0313b094782&#34;&gt;源码阅读&lt;/h2&gt;

&lt;h3 id=&#34;源码编译:34b0e58d062ee9acee54f0313b094782&#34;&gt;源码编译&lt;/h3&gt;

&lt;p&gt;按照官方文档的说明即可编译出来。其中几个需要的地方：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;提前下载好 go-bindata 的源码并编译出二进制出来安装的 $PATH 路径下&lt;/li&gt;
&lt;li&gt;提前下载好 glide 的源码并编译出二进制出来安装的 $PATH 路径下&lt;/li&gt;
&lt;li&gt;如果在windows下编译的话，trafik依赖的一个 &lt;code&gt;github.com/mailgun/log&lt;/code&gt; 库支持unix系统，需要做一下修改。将&lt;code&gt;NewSysLogger&lt;/code&gt;函数修改如下：&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func NewSysLogger(conf Config) (Logger, error) {
	debugW := os.Stdout
	infoW := os.Stdout
	warnW := os.Stdout
	errorW := os.Stdout

	sev, err := SeverityFromString(conf.Severity)
	if err != nil {
		return nil, err
	}

	return &amp;amp;sysLogger{sev, debugW, infoW, warnW, errorW}, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;http多路分发器-mux:34b0e58d062ee9acee54f0313b094782&#34;&gt;HTTP多路分发器：mux&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;github.com/gorilla/mux&lt;/code&gt; 是一个HTTP多路分发器，其原理也比较简单，就是实现了Golang标准库中的 &lt;code&gt;net.http.Handler&lt;/code&gt; 接口，即如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Handler interface {
    ServeHTTP(ResponseWriter, *Request)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当mux注册到HTTP服务之后，所有的HTTP请求就会由标准库 &lt;code&gt;net/http&lt;/code&gt; 转发到mux库中的 &lt;code&gt;func (r *Router) ServeHTTP(w http.ResponseWriter, req *http.Request)&lt;/code&gt; 函数中，
mux.Router.ServeHTTP这个函数再进行自己的路由规则匹配和转发。&lt;/p&gt;

&lt;p&gt;Trafik使用 &lt;code&gt;github.com/gorilla/mux&lt;/code&gt; 库做路由转发。&lt;/p&gt;

&lt;h2 id=&#34;参考:34b0e58d062ee9acee54f0313b094782&#34;&gt;参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.traefik.io/&#34;&gt;官方网站 https://docs.traefik.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/containous/traefik&#34;&gt;项目源码 https://github.com/containous/traefik&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>如何在win7 64位系统下安装gopcap包及使用</title>
      <link>http://blog.codeg.cn/post/blog/2016-05-26-howto-build-gopcap-on-windows-x64/</link>
      <pubDate>Wed, 25 May 2016 20:12:01 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/post/blog/2016-05-26-howto-build-gopcap-on-windows-x64/</guid>
      <description>

&lt;p&gt;&lt;code&gt;gopcap&lt;/code&gt;是libpcap库的Golang封装，其项目地址在这里 &lt;a href=&#34;https://github.com/akrennmair/gopcap&#34;&gt;https://github.com/akrennmair/gopcap&lt;/a&gt; 。
本文简要介绍一下如何在win7 64位系统平台上使用 &lt;code&gt;gopcap&lt;/code&gt; 库。&lt;/p&gt;

&lt;p&gt;安装步骤如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;安装Golang 64位版本&lt;/li&gt;
&lt;li&gt;安装mingw 64位版本，注意导入到windows环境变量中。让命令行能自动找到 gcc 命令&lt;/li&gt;
&lt;li&gt;在 &lt;a href=&#34;http://www.tcpdump.org/&#34;&gt;http://www.tcpdump.org/&lt;/a&gt; 下载 libpcap-1.7.4.tar.gz，从这个包中得到libpcap的C语言头文件&lt;/li&gt;
&lt;li&gt;在 &lt;a href=&#34;https://www.winpcap.org/install/&#34;&gt;https://www.winpcap.org/install/&lt;/a&gt; 下载winpcap并安装，从这里可以得到libpcap的windows DLL文件 wpcap.dll，用于运行&lt;/li&gt;
&lt;li&gt;在 &lt;a href=&#34;http://www.winpcap.org/archive/&#34;&gt;http://www.winpcap.org/archive/&lt;/a&gt; 下载 4.1.1-WpdPack.zip，从其中的x64目录下找到 wpcap.lib 库，用于编译&lt;/li&gt;
&lt;li&gt;执行下列命令：
&lt;pre&gt;
mkdir -p /c/wpdpcak/include
mkdir -p /c/wpdpcak/lib/x64
cp /c/Windows/System32/wpcap.dll /c/wpdpack/lib/x64/
cp -rf libpcap-1.7.4/Win32/Include/* /c/wpdpack/include/
cp -rf libpcap-1.7.4/pcap.h libpcap-1.7.4/pcap /c/wpdpack/include/
cp -rf 4.1.1-WpdPack/WpdPack/Lib/x64/wpcap.lib /c/wpdpcak/lib/x64
&lt;/pre&gt;
这里，将相关头文库、库文件都放在 &lt;code&gt;C:\wpdpcak&lt;/code&gt; 目录下，是因为 gopcap 库的cgo编译选择是这么设置，当然你也可以修改源码的方式来重新设置目录。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;编译过程中如果出现下列错误&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ go build
# github.com/akrennmair/gopcap
In file included from C:/WpdPack/Include/pcap.h:43:0,
          from ..\..\..\akrennmair\gopcap\pcap.go:12:
C:/WpdPack/Include/pcap/pcap.h:450:1: error: unknown type name &#39;Adapter&#39;
Adapter *pcap_get_adapter(pcap_t *p);
^
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就将 pcap/pcap.h 中这一行注释掉。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;至此，应该再不会有问题了，编译成功。 gopcap 库的toots目录有很多使用用例，可以看看以了解如何使用。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;参考:74f61569ed0f5a8ab78927a7660545ad&#34;&gt;参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.golang.org/c-go-cgo&#34;&gt;http://blog.golang.org/c-go-cgo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/akrennmair/gopcap&#34;&gt;https://github.com/akrennmair/gopcap&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Golang CGO编程之调用返回char*指针及长度的C函数库</title>
      <link>http://blog.codeg.cn/post/blog/2016-04-20-golang-cgo/</link>
      <pubDate>Wed, 20 Apr 2016 21:43:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/post/blog/2016-04-20-golang-cgo/</guid>
      <description>

&lt;p&gt;现代所有主流操作系统几乎都是用C语音实现的，几乎所有高级语言都能调用C语言，例如PHP可以调用C语言写的PHP扩展，Python也可以调用C语言实现的Python扩展。
Golang语言也不例外。&lt;/p&gt;

&lt;p&gt;Golang通过CGO机制能很方便的调用C语言。本文介绍一下如何在Go中调用稍稍复杂一点C函数，例如： &lt;code&gt;char* f(int, int*)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;首先看一个最简单的例子，将Golang中的一个字符串传入C函数中：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

/*
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
void print(char *str) {
    printf(&amp;quot;%s\n&amp;quot;, str);
}
*/
import &amp;quot;C&amp;quot;

import &amp;quot;unsafe&amp;quot;

func main() {
    s := &amp;quot;Hello Cgo&amp;quot;
    cs := C.CString(s)
    C.print(cs)
    C.free(unsafe.Pointer(cs))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意上述程序中的关键语句&lt;code&gt;cs := C.CString(s)&lt;/code&gt;是将一个Golang的字符串转换为C语言字符串，该C语言字符串是由C函数malloc从堆中分配的，因此后续需要调用 &lt;code&gt;C.free&lt;/code&gt; 释放内存。&lt;/p&gt;

&lt;p&gt;然后，我们看看如何调用一个复杂一点的C函数？例如： &lt;code&gt;char* f(int, int*)&lt;/code&gt; ，返回一个&lt;code&gt;char*&lt;/code&gt;指针，并且有一个参数也是返回值&lt;code&gt;int*&lt;/code&gt;。请直接看下面的例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

/*
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
char* xmalloc(int len, int *rlen)
{
    static const char* s = &amp;quot;0123456789&amp;quot;;
    char* p = malloc(len);
    if (len &amp;lt;= strlen(s)) {
        memcpy(p, s, len);
    } else {
        memset(p, &#39;a&#39;, len);
    }
    *rlen = len;
    return p;
}
*/
import &amp;quot;C&amp;quot;
import &amp;quot;unsafe&amp;quot;
import &amp;quot;fmt&amp;quot;

func main() {
	rlen := C.int(0)
	len := 10
	cstr := C.xmalloc(C.int(len), &amp;amp;rlen)
	defer C.free(unsafe.Pointer(cstr))
	gostr := C.GoStringN(cstr, rlen)
	fmt.Printf(&amp;quot;retlen=%v\n&amp;quot;, rlen)
	println(gostr)
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;xmalloc&lt;/code&gt;函数的第二个参数是&lt;code&gt;int*&lt;/code&gt;，这里设计为一个输入、输出参数。我们在Golang中使用C.int类型的指针就可以；
其返回值是一个&lt;code&gt;char*&lt;/code&gt;，在Golang中就是 &lt;code&gt;*C.char&lt;/code&gt;，由于返回值是指针，其内存由malloc分配，因此需要在Golang中对其内存进行释放。&lt;/p&gt;

&lt;p&gt;再然后，我们看看如何调用一个返回结构体的C函数？例如：&lt;code&gt;struct MyString xmalloc(int len)&lt;/code&gt;。请看示例代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

/*
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;

struct MyString
{
    char* s;
    int len;
};

struct MyString xmalloc(int len)
{
    static const char* s = &amp;quot;0123456789&amp;quot;;
    char* p = malloc(len);
    if (len &amp;lt;= strlen(s)) {
        memcpy(p, s, len);
    } else {
        memset(p, &#39;a&#39;, len);
    }
    struct MyString str;
    str.s = p;
    str.len = len;
    return str;
}
*/
import &amp;quot;C&amp;quot;
import &amp;quot;unsafe&amp;quot;
import &amp;quot;fmt&amp;quot;

func main() {
	len := 10
	str := C.xmalloc(C.int(len))
	defer C.free(unsafe.Pointer(str.s))
	gostr := C.GoStringN(str.s, str.len)
	fmt.Printf(&amp;quot;retlen=%v\n&amp;quot;, str.len)
	println(gostr)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考:1d9c7bc1f63996ea5a05ef9bf93a075a&#34;&gt;参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.golang.org/c-go-cgo&#34;&gt;http://blog.golang.org/c-go-cgo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://golang.org/cmd/cgo/&#34;&gt;https://golang.org/cmd/cgo/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>使用Golang利用ectd实现一个分布式锁</title>
      <link>http://blog.codeg.cn/post/blog/2016-02-24-distrubute-lock-over-etcd/</link>
      <pubDate>Wed, 24 Feb 2016 20:43:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/post/blog/2016-02-24-distrubute-lock-over-etcd/</guid>
      <description>

&lt;p&gt;&lt;code&gt;etcd&lt;/code&gt;是随着&lt;code&gt;CoreOS&lt;/code&gt;项目一起成长起来的，随着Golang和CoreOS等项目在开源社区日益火热，
&lt;code&gt;etcd&lt;/code&gt;作为一个高可用、强一致性的分布式Key-Value存储系统被越来越多的开发人员关注和使用。&lt;/p&gt;

&lt;p&gt;这篇&lt;a href=&#34;http://www.infoq.com/cn/articles/etcd-interpretation-application-scenario-implement-principle&#34;&gt;文章&lt;/a&gt;全方位介绍了etcd的应用场景，这里简单摘要如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;服务发现（Service Discovery）&lt;/li&gt;
&lt;li&gt;消息发布与订阅&lt;/li&gt;
&lt;li&gt;负载均衡&lt;/li&gt;
&lt;li&gt;分布式通知与协调&lt;/li&gt;
&lt;li&gt;分布式锁&lt;/li&gt;
&lt;li&gt;分布式队列&lt;/li&gt;
&lt;li&gt;集群监控与Leader竞选&lt;/li&gt;
&lt;li&gt;为什么用etcd而不用ZooKeeper&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文重点介绍如何利用&lt;code&gt;ectd&lt;/code&gt;实现一个分布式锁。
锁的概念大家都熟悉，当我们希望某一事件在同一时间点只有一个线程(goroutine)在做，或者某一个资源在同一时间点只有一个服务能访问，这个时候我们就需要用到锁。
例如我们要实现一个分布式的id生成器，多台服务器之间的协调就非常麻烦。分布式锁就正好派上用场。&lt;/p&gt;

&lt;p&gt;其基本实现原理为：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;在ectd系统里创建一个key&lt;/li&gt;
&lt;li&gt;如果创建失败，key存在，则监听该key的变化事件，直到该key被删除，回到1&lt;/li&gt;
&lt;li&gt;如果创建成功，则认为我获得了锁&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;具体代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package etcdsync

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;io&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;sync&amp;quot;
	&amp;quot;time&amp;quot;

	&amp;quot;github.com/coreos/etcd/client&amp;quot;
	&amp;quot;github.com/coreos/etcd/Godeps/_workspace/src/golang.org/x/net/context&amp;quot;
)

const (
	defaultTTL = 60
	defaultTry = 3
	deleteAction = &amp;quot;delete&amp;quot;
	expireAction = &amp;quot;expire&amp;quot;
)

// A Mutex is a mutual exclusion lock which is distributed across a cluster.
type Mutex struct {
	key    string
	id     string // The identity of the caller
	client client.Client
	kapi   client.KeysAPI
	ctx    context.Context
	ttl    time.Duration
	mutex  *sync.Mutex
	logger io.Writer
}

// New creates a Mutex with the given key which must be the same
// across the cluster nodes.
// machines are the ectd cluster addresses
func New(key string, ttl int, machines []string) *Mutex {
	cfg := client.Config{
		Endpoints:               machines,
		Transport:               client.DefaultTransport,
		HeaderTimeoutPerRequest: time.Second,
	}

	c, err := client.New(cfg)
	if err != nil {
		return nil
	}

	hostname, err := os.Hostname()
	if err != nil {
		return nil
	}

	if len(key) == 0 || len(machines) == 0 {
		return nil
	}

	if key[0] != &#39;/&#39; {
		key = &amp;quot;/&amp;quot; + key
	}

	if ttl &amp;lt; 1 {
		ttl = defaultTTL
	}

	return &amp;amp;Mutex{
		key:    key,
		id:     fmt.Sprintf(&amp;quot;%v-%v-%v&amp;quot;, hostname, os.Getpid(), time.Now().Format(&amp;quot;20060102-15:04:05.999999999&amp;quot;)),
		client: c,
		kapi:   client.NewKeysAPI(c),
		ctx: context.TODO(),
		ttl: time.Second * time.Duration(ttl),
		mutex:  new(sync.Mutex),
	}
}

// Lock locks m.
// If the lock is already in use, the calling goroutine
// blocks until the mutex is available.
func (m *Mutex) Lock() (err error) {
	m.mutex.Lock()
	for try := 1; try &amp;lt;= defaultTry; try++ {
		if m.lock() == nil {
			return nil
		}
		
		m.debug(&amp;quot;Lock node %v ERROR %v&amp;quot;, m.key, err)
		if try &amp;lt; defaultTry {
			m.debug(&amp;quot;Try to lock node %v again&amp;quot;, m.key, err)
		}
	}
	return err
}

func (m *Mutex) lock() (err error) {
	m.debug(&amp;quot;Trying to create a node : key=%v&amp;quot;, m.key)
	setOptions := &amp;amp;client.SetOptions{
		PrevExist:client.PrevNoExist,
		TTL:      m.ttl,
	}
	resp, err := m.kapi.Set(m.ctx, m.key, m.id, setOptions)
	if err == nil {
		m.debug(&amp;quot;Create node %v OK [%q]&amp;quot;, m.key, resp)
		return nil
	}
	m.debug(&amp;quot;Create node %v failed [%v]&amp;quot;, m.key, err)
	e, ok := err.(client.Error)
	if !ok {
		return err
	}

	if e.Code != client.ErrorCodeNodeExist {
		return err
	}

	// Get the already node&#39;s value.
	resp, err = m.kapi.Get(m.ctx, m.key, nil)
	if err != nil {
		return err
	}
	m.debug(&amp;quot;Get node %v OK&amp;quot;, m.key)
	watcherOptions := &amp;amp;client.WatcherOptions{
		AfterIndex : resp.Index,
		Recursive:false,
	}
	watcher := m.kapi.Watcher(m.key, watcherOptions)
	for {
		m.debug(&amp;quot;Watching %v ...&amp;quot;, m.key)
		resp, err = watcher.Next(m.ctx)
		if err != nil {
			return err
		}

		m.debug(&amp;quot;Received an event : %q&amp;quot;, resp)
		if resp.Action == deleteAction || resp.Action == expireAction {
			return nil
		}
	}

}

// Unlock unlocks m.
// It is a run-time error if m is not locked on entry to Unlock.
//
// A locked Mutex is not associated with a particular goroutine.
// It is allowed for one goroutine to lock a Mutex and then
// arrange for another goroutine to unlock it.
func (m *Mutex) Unlock() (err error) {
	defer m.mutex.Unlock()
	for i := 1; i &amp;lt;= defaultTry; i++ {
		var resp *client.Response
		resp, err = m.kapi.Delete(m.ctx, m.key, nil)
		if err == nil {
			m.debug(&amp;quot;Delete %v OK&amp;quot;, m.key)
			return nil
		}
		m.debug(&amp;quot;Delete %v falied: %q&amp;quot;, m.key, resp)
		e, ok := err.(client.Error)
		if ok &amp;amp;&amp;amp; e.Code == client.ErrorCodeKeyNotFound {
			return nil
		}
	}
	return err
}

func (m *Mutex) debug(format string, v ...interface{}) {
	if m.logger != nil {
		m.logger.Write([]byte(m.id))
		m.logger.Write([]byte(&amp;quot; &amp;quot;))
		m.logger.Write([]byte(fmt.Sprintf(format, v...)))
		m.logger.Write([]byte(&amp;quot;\n&amp;quot;))
	}
}

func (m *Mutex) SetDebugLogger(w io.Writer) {
	m.logger = w
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实类似的实现有很多，但目前都已经过时，使用的都是被官方标记为&lt;code&gt;deprecated&lt;/code&gt;的项目。且大部分接口都不如上述代码简单。
使用上，跟Golang官方sync包的Mutex接口非常类似，先&lt;code&gt;New()&lt;/code&gt;，然后调用&lt;code&gt;Lock()&lt;/code&gt;，使用完后调用&lt;code&gt;Unlock()&lt;/code&gt;，就三个接口，就是这么简单。示例代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;github.com/zieckey/etcdsync&amp;quot;
	&amp;quot;log&amp;quot;
)

func main() {
	//etcdsync.SetDebug(true)
	log.SetFlags(log.Ldate|log.Ltime|log.Lshortfile)
	m := etcdsync.New(&amp;quot;/etcdsync&amp;quot;, &amp;quot;123&amp;quot;, []string{&amp;quot;http://127.0.0.1:2379&amp;quot;})
	if m == nil {
		log.Printf(&amp;quot;etcdsync.NewMutex failed&amp;quot;)
	}
	err := m.Lock()
	if err != nil {
		log.Printf(&amp;quot;etcdsync.Lock failed&amp;quot;)
	} else {
		log.Printf(&amp;quot;etcdsync.Lock OK&amp;quot;)
	}

	log.Printf(&amp;quot;Get the lock. Do something here.&amp;quot;)

	err = m.Unlock()
	if err != nil {
		log.Printf(&amp;quot;etcdsync.Unlock failed&amp;quot;)
	} else {
		log.Printf(&amp;quot;etcdsync.Unlock OK&amp;quot;)
	}
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考:cc4776a5974d000eb2d6ff22e22b2c04&#34;&gt;参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/zieckey/etcdsync&#34;&gt;etcdsync项目地址&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/etcd&#34;&gt;ectd项目官方地址&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>编译Golang包为C语言库文件</title>
      <link>http://blog.codeg.cn/2016/02/19/sharing-golang-package-to-C/</link>
      <pubDate>Fri, 19 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/2016/02/19/sharing-golang-package-to-C/</guid>
      <description>

&lt;p&gt;Go 1.5发布后，其包含一个特性：可以编译生成C语言动态链接库或静态库。本文给出了示例代码和用法。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;go build&lt;/code&gt;和&lt;code&gt;go install&lt;/code&gt;命令，可以使用参数 &lt;code&gt;-buildmode&lt;/code&gt; 来指定生成哪种类型的二进制目标文件。请见&lt;a href=&#34;https://golang.org/cmd/go/&#34;&gt;https://golang.org/cmd/go/#Description of build modes&lt;/a&gt; 详细说明。&lt;/p&gt;

&lt;p&gt;当前我们使用 &lt;code&gt;-buildmode=c-archive&lt;/code&gt; 来示例和测试。&lt;/p&gt;

&lt;p&gt;Golang源文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;
// file hello.go
package main

  port &amp;quot;C&amp;quot;
import &amp;quot;fmt&amp;quot;

//export SayHello
func SayHello(name string) {
    fmt.Printf(&amp;quot;func in Golang SayHello says: Hello, %s!\n&amp;quot;, name)
}

//export SayHelloByte
func SayHelloByte(name []byte) {
    fmt.Printf(&amp;quot;func in Golang SayHelloByte says: Hello, %s!\n&amp;quot;, string(name))
}

//export SayBye
func SayBye() {
    fmt.Println(&amp;quot;func in Golang SayBye says: Bye!&amp;quot;)
}

func main() {
    // We need the main function to make possible
    // CGO compiler to compile the package as C shared library
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用命令&lt;code&gt;go build -buildmode=c-archive -o libhello.a hello.go&lt;/code&gt;可以生成一个C语言静态库&lt;code&gt;libhello.a&lt;/code&gt;和头文件&lt;code&gt;libhello.h&lt;/code&gt;。
然后我们再写个C语言程序来调用这个库，如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// file hello.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;quot;libhello.h&amp;quot;

int main() {
  printf(&amp;quot;This is a C Application.\n&amp;quot;);
  GoString name = {(char*)&amp;quot;Jane&amp;quot;, 4};
  SayHello(name);
  GoSlice buf = {(void*)&amp;quot;Jane&amp;quot;, 4, 4};
  SayHelloByte(buf);
  SayBye();
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用命令&lt;code&gt;gcc -o hello hello.c libhello.a -pthread&lt;/code&gt;来编译生成一个可执行文件&lt;code&gt;hello&lt;/code&gt;。执行命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ go build -buildmode=c-archive -o libhello.a hello.go
$ gcc -o hello hello.c libhello.a -pthread
$ ./hello 
This is a C Application.
func in Golang SayHello says: Hello, Jane!
func in Golang SayHelloByte says: Hello, Jane!
func in Golang SayBye says: Bye!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;备注：目前Golang还不支持将一个struct结构导出到C库中。&lt;/p&gt;

&lt;h2 id=&#34;参考:d07f2a12ab89ca994adea10c36662f05&#34;&gt;参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.ralch.com/tutorial/golang-sharing-libraries/&#34;&gt;Sharing Golang packages to C and Go&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Golang发送邮件</title>
      <link>http://blog.codeg.cn/2016/02/14/send-email-for-golang/</link>
      <pubDate>Sun, 14 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/2016/02/14/send-email-for-golang/</guid>
      <description>

&lt;p&gt;本文介绍一个简单的方法使用Go语言发送邮件。直接调用系统自带的&lt;code&gt;mail&lt;/code&gt;命令发送邮件。&lt;/p&gt;

&lt;p&gt;在网上找了很多例子，基本上都是基于Golang本身自带的&lt;code&gt;smtp&lt;/code&gt;包来实现的，参考 &lt;a href=&#34;http://www.tuicool.com/articles/e2qUv2&#34;&gt;http://www.tuicool.com/articles/e2qUv2&lt;/a&gt;，这里需要以下几个关键信息：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;邮箱地址(邮箱用户名)&lt;/li&gt;
&lt;li&gt;邮箱密码&lt;/li&gt;
&lt;li&gt;邮件提供商hostname&lt;/li&gt;
&lt;li&gt;smtp服务器地址和端口&lt;/li&gt;
&lt;li&gt;邮件主题、正文、接收人列表&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上述5个信息中，实际上我们关心的其实只有第5个，其他4个都不是太关心。而且，如果我们想写一段开源代码，这里就把邮箱用户名和密码给暴露了，不太合适。我于是想到了PHP中的&lt;code&gt;mail&lt;/code&gt;这个发送邮件的函数来，PHP是如何实现邮件发送的功能呢？我搜素PHP的源码发现在非Windows平台使用的系统自带的&lt;code&gt;sendmail&lt;/code&gt;命令来发送的，具体代码请参考: php-5.3.3/ext/standard/mail.c:php_mail&lt;/p&gt;

&lt;p&gt;受此启发，我在golang中也这么实现不就简单了么？下面是源码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (
	&amp;quot;os/exec&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;runtime&amp;quot;
)

// SendMail sends an email to the addresses using &#39;mail&#39; command on *nux platform.
func SendMail(title, message string, email ...string) error {
	if runtime.GOOS == &amp;quot;windows&amp;quot; {
		log.Printf(&amp;quot;TODO: cannot send email on windows title=[%v] messagebody=[%v]&amp;quot;, title, message)
		return nil
	}
	mailCommand := exec.Command(&amp;quot;mail&amp;quot;, &amp;quot;-s&amp;quot;, title)
	mailCommand.Args = append(mailCommand.Args, email...)
	stdin, err := mailCommand.StdinPipe()
	if err != nil {
		log.Printf(&amp;quot;StdinPipe failed to perform: %s (Command: %s, Arguments: %s)&amp;quot;, err, mailCommand.Path, mailCommand.Args)
		return err
	}
	stdin.Write([]byte(message))
	stdin.Close()
	_, err = mailCommand.Output()
	if err != nil || !mailCommand.ProcessState.Success() {
		log.Printf(&amp;quot;send email ERROR : &amp;lt;%v&amp;gt; title=[%v] messagebody=[%v]&amp;quot;, err.Error(), title, message)
		return err
	}

	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上述源码放到这里了： &lt;a href=&#34;https://github.com/zieckey/gocom/tree/master/tmail&#34;&gt;https://github.com/zieckey/gocom/tree/master/tmail&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;参考:6819fbcd570de1ca567e85fb36deeb5f&#34;&gt;参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.tuicool.com/articles/e2qUv2&#34;&gt;Golang Go语言发送邮件的方法&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Golang版本的remove_if函数实现</title>
      <link>http://blog.codeg.cn/2016/02/14/golang-remove_if/</link>
      <pubDate>Sun, 14 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/2016/02/14/golang-remove_if/</guid>
      <description>&lt;p&gt;C++中的std::remove_if函数实现了一个算法，可以将一个容器中的元素按照一定的规则进行删除，但Go语言中却没有类似的函数。代码其实很简单，如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func RemoveIf(s string, f func(rune) bool) string {
	runes := []rune(s)
	result := 0
	for i, r := range runes  {
		if !f(r) {
			runes[result] = runes[i]
			result++
		}
	}

	return string(runes[0:result])
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上述算法是参考C++标准库中的实现(&lt;code&gt;bits/stl_algo.h:remove_if&lt;/code&gt;)，但比C++的效率低，因为多了两次转换（&lt;code&gt;string&lt;/code&gt;与&lt;code&gt;[]rune&lt;/code&gt;互相转换两次）。&lt;/p&gt;

&lt;p&gt;进一步思考：这两次转换不知道是否可以通过其他方式节省掉？类似于C++的实现，就地删除（并没有新开辟内存空间）。&lt;/p&gt;

&lt;p&gt;上述源码放到这里了： &lt;a href=&#34;https://github.com/zieckey/gocom/tree/master/tstrings&#34;&gt;https://github.com/zieckey/gocom/tree/master/tstrings&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;必须要吐槽一下Go语言没有泛型，如果要针对&lt;code&gt;[]byte&lt;/code&gt;就又得要重复实现一遍类似的代码。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用grafana&#43;influxdb搭建炫酷的实时可视化监控平台</title>
      <link>http://blog.codeg.cn/2016/02/05/influxdb-grafana/</link>
      <pubDate>Fri, 05 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/2016/02/05/influxdb-grafana/</guid>
      <description>

&lt;p&gt;最近看到一篇介绍influxdb的文章，然后又看到用grafana配合图形展示，就简单试用了一下，确实还不错。但其中也遇到一些低级问题，这篇博文就当一个流水文档吧，便于以后查阅。&lt;/p&gt;

&lt;p&gt;这几个组件的使用方式为：数据收集 &amp;ndash;&amp;gt; influxdb存储 &amp;ndash;&amp;gt; grafana展现。&lt;/p&gt;

&lt;p&gt;本文所述的influxdb版本适用于为0.9x，grafana版本适用于2.6&lt;/p&gt;

&lt;h2 id=&#34;influxdb介绍:9d3466cfc8ab63c666c05dcaaea0b79f&#34;&gt;influxdb介绍&lt;/h2&gt;

&lt;p&gt;InfluxDB 是一个开源分布式的时序、事件和指标数据库。使用 Go 语言编写，无需外部依赖。其设计目标是实现分布式和水平伸缩扩展。
它有三大特性：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Time Series （时间序列）：你可以使用与时间有关的相关函数（如最大，最小，求和等）&lt;/li&gt;
&lt;li&gt;Metrics（度量）：你可以实时对大量数据进行计算&lt;/li&gt;
&lt;li&gt;Eevents（事件）：它支持任意的事件数据&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;又有如下特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;schemaless(无结构)，可以是任意数量的列&lt;/li&gt;
&lt;li&gt;Scalable&lt;/li&gt;
&lt;li&gt;min, max, sum, count, mean, median 一系列函数，方便统计&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;按照其官方文档，可以很方便的在centos上安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF | sudo tee /etc/yum.repos.d/influxdb.repo
[influxdb]
name = InfluxDB Repository - RHEL \$releasever
baseurl = https://repos.influxdata.com/rhel/\$releasever/\$basearch/stable
enabled = 1
gpgcheck = 1
gpgkey = https://repos.influxdata.com/influxdb.key
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后使用yum安装：
    sudo yum install influxdb&lt;/p&gt;

&lt;p&gt;直接在前台启动也很方便，输入命令 &lt;code&gt;influxdb&lt;/code&gt; 即可启动。&lt;/p&gt;

&lt;p&gt;默认情况下influxdb会监听一下端口：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;8083端口，供HTTP web管理平台使用。&lt;/li&gt;
&lt;li&gt;8086端口，供HTTP API接口使用，例如写入数据、查询数据等等&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;grafana介绍:9d3466cfc8ab63c666c05dcaaea0b79f&#34;&gt;grafana介绍&lt;/h2&gt;

&lt;p&gt;grafana 是以纯 Javascript 开发的前端工具，用于访问 InfluxDB，自定义报表、显示图表等。&lt;/p&gt;

&lt;h3 id=&#34;安装-grafana:9d3466cfc8ab63c666c05dcaaea0b79f&#34;&gt;安装 grafana&lt;/h3&gt;

&lt;p&gt;在其&lt;a href=&#34;http://grafana.org/download/&#34;&gt;官网http://grafana.org/download/&lt;/a&gt;可以下载合适的安装包。安装也很方便。&lt;/p&gt;

&lt;h3 id=&#34;添加数据源-influxdb:9d3466cfc8ab63c666c05dcaaea0b79f&#34;&gt;添加数据源：influxdb&lt;/h3&gt;

&lt;p&gt;我们将 influxdb 添加到 grafana 的数据源中，按照其&lt;a href=&#34;http://docs.grafana.org/datasources/influxdb/&#34;&gt;官方文档http://docs.grafana.org/datasources/influxdb/&lt;/a&gt;操作起来也方便。&lt;/p&gt;

&lt;h3 id=&#34;图形展现:9d3466cfc8ab63c666c05dcaaea0b79f&#34;&gt;图形展现&lt;/h3&gt;

&lt;p&gt;在这里我耗了好久才搞明白怎么通过图形方式将 influxdb 的数据在 grafana web中展现出来。请按照下图中操作即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.codeg.cn/images/githubpages/grafana/1.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://blog.codeg.cn/images/githubpages/grafana/2.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://blog.codeg.cn/images/githubpages/grafana/3.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://blog.codeg.cn/images/githubpages/grafana/4.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://blog.codeg.cn/images/githubpages/grafana/5.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://blog.codeg.cn/images/githubpages/grafana/6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;更多功能还有待发掘。&lt;/p&gt;

&lt;h2 id=&#34;参考:9d3466cfc8ab63c666c05dcaaea0b79f&#34;&gt;参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.grafana.org/datasources/influxdb/&#34;&gt;grafana官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.influxdata.com/influxdb/v0.9/introduction/getting_started/&#34;&gt;influxdb官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://download.csdn.net/detail/shuijinglei1988/9113655&#34;&gt;Grafana的入门级使用-自制教程-结合InfluxDB使用&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>源码阅读-悟空搜索引擎</title>
      <link>http://blog.codeg.cn/2016/02/02/wukong-source-code-reading/</link>
      <pubDate>Tue, 02 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/2016/02/02/wukong-source-code-reading/</guid>
      <description>

&lt;h2 id=&#34;一个最简单的例子:89e0d5dad305327940f268393030b521&#34;&gt;一个最简单的例子&lt;/h2&gt;

&lt;p&gt;我们还是从一个最简单的示例代码开始：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;github.com/huichen/wukong/engine&amp;quot;
	&amp;quot;github.com/huichen/wukong/types&amp;quot;
	&amp;quot;log&amp;quot;
)

var (
// searcher是协程安全的
	searcher = engine.Engine{}
)

func main() {
	// 初始化
	searcher.Init(types.EngineInitOptions{
		SegmenterDictionaries: &amp;quot;./data/dictionary.txt&amp;quot;})
	defer searcher.Close()

	// 将文档加入索引
	searcher.IndexDocument(0, types.DocumentIndexData{Content: &amp;quot;此次百度收购将成中国互联网最大并购&amp;quot;})
	searcher.IndexDocument(1, types.DocumentIndexData{Content: &amp;quot;百度宣布拟全资收购91无线业务&amp;quot;})
	searcher.IndexDocument(2, types.DocumentIndexData{Content: &amp;quot;百度是中国最大的搜索引擎&amp;quot;})

	// 等待索引刷新完毕
	searcher.FlushIndex()

	// 搜索输出格式见types.SearchResponse结构体
	res := searcher.Search(types.SearchRequest{Text:&amp;quot;百度中国&amp;quot;})
	log.Printf(&amp;quot;num=%d &amp;quot;, res.NumDocs)
	for _, d := range res.Docs {
		log.Printf(&amp;quot;docId=%d&amp;quot;, d.DocId)
		log.Print(&amp;quot;\tscore:&amp;quot;, d.Scores)
		log.Print(&amp;quot;\tTokenLocations:&amp;quot;, d.TokenLocations)
		log.Print(&amp;quot;\tTokenSnippetLocations:&amp;quot;, d.TokenSnippetLocations)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;悟空搜索引擎不是一个完整的搜索引擎，我们可以把它当做一个搜索引擎基础库来使用。上面的示例代码是一个最简单的例子，展示了如何使用这个库，非常简单，三步即可完成：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;初始化引擎： &lt;code&gt;searcher.Init&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;将文档加入索引列表中： &lt;code&gt;searcher.IndexDocument&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;执行搜索任务：&lt;code&gt;searcher.Search&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;悟空搜索引擎内部整体框架图:89e0d5dad305327940f268393030b521&#34;&gt;悟空搜索引擎内部整体框架图&lt;/h2&gt;

&lt;p&gt;引擎中处理用户请求、分词、索引和排序分别由不同的协程（goroutines）完成。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;主协程，用于收发用户请求&lt;/li&gt;
&lt;li&gt;分词器（segmenter）协程，负责分词&lt;/li&gt;
&lt;li&gt;索引器（indexer）协程，负责建立和查找索引表&lt;/li&gt;
&lt;li&gt;排序器（ranker）协程，负责对文档评分排序&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.codeg.cn/images/githubpages/wukong-framework.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;引擎初始化过程:89e0d5dad305327940f268393030b521&#34;&gt;引擎初始化过程&lt;/h2&gt;

&lt;p&gt;从上面最简单的那个例子可以看出，我们所有的操作都是基于&lt;code&gt;searcher&lt;/code&gt;对象（engine.Engine类型），初始化引擎、将文档加入索引列表中、Flush索引列表、执行搜索任务。下面我们详细分析一下初始化过程：&lt;/p&gt;

&lt;h4 id=&#34;加载分词词典:89e0d5dad305327940f268393030b521&#34;&gt;加载分词词典&lt;/h4&gt;

&lt;p&gt;有一个参数&lt;code&gt;NotUsingSegmenter&lt;/code&gt;可以控制是否加载分词词典。小小吐槽一下：这里没有使用正语义，导致我脑袋需要非非转换，(⊙o⊙)… ，我相信如果使用&lt;code&gt;UsingSegmenter&lt;/code&gt;参数的话，应该更好理解一点。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	if !options.NotUsingSegmenter {
		// 载入分词器词典
		engine.segmenter.LoadDictionary(options.SegmenterDictionaries)

		// 初始化停用词
		engine.stopTokens.Init(options.StopTokenFile)
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;分词词典的内部加载过程，可以详细参考 &lt;code&gt;https://github.com/huichen/sego&lt;/code&gt; 这个项目，这个可以单独来分析，在这里就不在展开说了。&lt;/p&gt;

&lt;h4 id=&#34;初始化索引器和排序器:89e0d5dad305327940f268393030b521&#34;&gt;初始化索引器和排序器&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	for shard := 0; shard &amp;lt; options.NumShards; shard++ {
		engine.indexers = append(engine.indexers, core.Indexer{})
		engine.indexers[shard].Init(*options.IndexerInitOptions)

		engine.rankers = append(engine.rankers, core.Ranker{})
		engine.rankers[shard].Init()
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;options.NumShards&lt;/code&gt; 参数可以设置&lt;code&gt;shard&lt;/code&gt;(分片，项目作者称之为裂分)个数，根据&lt;code&gt;shard&lt;/code&gt;个数来初始化索引器(Indexer)、排序器(Rander)的个数。这里是为了方便并行处理，每一个&lt;code&gt;shard&lt;/code&gt;都有一个索引器(Indexer)和排序器(Rander)，并提前初始化好。&lt;/p&gt;

&lt;h4 id=&#34;初始化分词器通道:89e0d5dad305327940f268393030b521&#34;&gt;初始化分词器通道&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	engine.segmenterChannel = make(
		chan segmenterRequest, options.NumSegmenterThreads)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;初始化索引器通道:89e0d5dad305327940f268393030b521&#34;&gt;初始化索引器通道&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	engine.indexerAddDocumentChannels = make(
		[]chan indexerAddDocumentRequest, options.NumShards)
	engine.indexerRemoveDocChannels = make(
		[]chan indexerRemoveDocRequest, options.NumShards)
	engine.indexerLookupChannels = make(
		[]chan indexerLookupRequest, options.NumShards)
	for shard := 0; shard &amp;lt; options.NumShards; shard++ {
		engine.indexerAddDocumentChannels[shard] = make(
			chan indexerAddDocumentRequest,
			options.IndexerBufferLength)
		engine.indexerRemoveDocChannels[shard] = make(
			chan indexerRemoveDocRequest,
			options.IndexerBufferLength)
		engine.indexerLookupChannels[shard] = make(
			chan indexerLookupRequest,
			options.IndexerBufferLength)
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从这里可以看出索引器(Indexer)有三个功能：将一个文档添加到索引中、将一个文档从索引中移除、从索引中查找一个文档。每一个&lt;code&gt;shard&lt;/code&gt;都有独立的&lt;code&gt;channel&lt;/code&gt;，互不冲突。&lt;/p&gt;

&lt;h4 id=&#34;初始化排序器通道:89e0d5dad305327940f268393030b521&#34;&gt;初始化排序器通道&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	engine.rankerAddDocChannels = make(
		[]chan rankerAddDocRequest, options.NumShards)
	engine.rankerRankChannels = make(
		[]chan rankerRankRequest, options.NumShards)
	engine.rankerRemoveDocChannels = make(
		[]chan rankerRemoveDocRequest, options.NumShards)
	for shard := 0; shard &amp;lt; options.NumShards; shard++ {
		engine.rankerAddDocChannels[shard] = make(
			chan rankerAddDocRequest,
			options.RankerBufferLength)
		engine.rankerRankChannels[shard] = make(
			chan rankerRankRequest,
			options.RankerBufferLength)
		engine.rankerRemoveDocChannels[shard] = make(
			chan rankerRemoveDocRequest,
			options.RankerBufferLength)
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;与上面类似，从这里可以看出排序器(Rander)有三个功能：将一个文档添加到排序器中、在排序器中进行排序、将一个文档从排序器中移除。每一个&lt;code&gt;shard&lt;/code&gt;都有独立的&lt;code&gt;channel&lt;/code&gt;，互不冲突。&lt;/p&gt;

&lt;h4 id=&#34;初始化持久化存储通道:89e0d5dad305327940f268393030b521&#34;&gt;初始化持久化存储通道&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	if engine.initOptions.UsePersistentStorage {
		engine.persistentStorageIndexDocumentChannels =
			make([]chan persistentStorageIndexDocumentRequest,
				engine.initOptions.PersistentStorageShards)
		for shard := 0; shard &amp;lt; engine.initOptions.PersistentStorageShards; shard++ {
			engine.persistentStorageIndexDocumentChannels[shard] = make(
				chan persistentStorageIndexDocumentRequest)
		}
		engine.persistentStorageInitChannel = make(
			chan bool, engine.initOptions.PersistentStorageShards)
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意：&lt;code&gt;PersistentStorageShards&lt;/code&gt;持久化存储的分片数目是独立参数控制的。&lt;/p&gt;

&lt;h4 id=&#34;启动各个功能协程goroutine:89e0d5dad305327940f268393030b521&#34;&gt;启动各个功能协程goroutine&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;启动分词器协程&lt;/li&gt;
&lt;li&gt;启动索引器和排序器协程&lt;/li&gt;
&lt;li&gt;启动持久化存储工作协程&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;至此，所有初始化工作完毕。&lt;/p&gt;

&lt;h2 id=&#34;索引过程分析:89e0d5dad305327940f268393030b521&#34;&gt;索引过程分析&lt;/h2&gt;

&lt;p&gt;下面我们来分析索引过程。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// 将文档加入索引
//
// 输入参数：
// 	docId	标识文档编号，必须唯一
//	data	见DocumentIndexData注释
//
// 注意：
//      1. 这个函数是线程安全的，请尽可能并发调用以提高索引速度
// 	2. 这个函数调用是非同步的，也就是说在函数返回时有可能文档还没有加入索引中，因此
//         如果立刻调用Search可能无法查询到这个文档。强制刷新索引请调用FlushIndex函数。
func (engine *Engine) IndexDocument(docId uint64, data types.DocumentIndexData) {
	engine.internalIndexDocument(docId, data)

	hash := murmur.Murmur3([]byte(fmt.Sprint(&amp;quot;%d&amp;quot;, docId))) % uint32(engine.initOptions.PersistentStorageShards)
	if engine.initOptions.UsePersistentStorage {
		engine.persistentStorageIndexDocumentChannels[hash] &amp;lt;- persistentStorageIndexDocumentRequest{docId: docId, data: data}
	}
}

func (engine *Engine) internalIndexDocument(docId uint64, data types.DocumentIndexData) {
	if !engine.initialized {
		log.Fatal(&amp;quot;必须先初始化引擎&amp;quot;)
	}

	atomic.AddUint64(&amp;amp;engine.numIndexingRequests, 1)
	hash := murmur.Murmur3([]byte(fmt.Sprint(&amp;quot;%d%s&amp;quot;, docId, data.Content)))
	engine.segmenterChannel &amp;lt;- segmenterRequest{
		docId: docId, hash: hash, data: data}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里需要注意的是，docId参数需要调用者从外部传入，而不是在内部自己创建，这给搜索引擎的实现者更大的自由。
将文档交给分词器处理，然后根据murmur3计算的hash值模&lt;code&gt;PersistentStorageShards&lt;/code&gt;，选择合适的&lt;code&gt;shard&lt;/code&gt;写入持久化存储中。&lt;/p&gt;

&lt;h3 id=&#34;索引过程分析-分词协程处理过程:89e0d5dad305327940f268393030b521&#34;&gt;索引过程分析：分词协程处理过程&lt;/h3&gt;

&lt;p&gt;分词器协程的逻辑代码在这里：&lt;code&gt;segmenter_worker.go:func (engine *Engine) segmenterWorker()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;分词器协程的逻辑是一个死循环，不停的从&lt;code&gt;channel engine.segmenterChannel&lt;/code&gt;中读取数据，针对每一次读取的数据：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;计算&lt;code&gt;shard&lt;/code&gt;号&lt;/li&gt;
&lt;li&gt;将文档分词&lt;/li&gt;
&lt;li&gt;根据分词结果，构造&lt;code&gt;indexerAddDocumentRequest&lt;/code&gt; 和 &lt;code&gt;rankerAddDocRequest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;将&lt;code&gt;indexerAddDocumentRequest&lt;/code&gt;投递到&lt;code&gt;channel engine.indexerAddDocumentChannels[shard]&lt;/code&gt;中&lt;/li&gt;
&lt;li&gt;将&lt;code&gt;rankerAddDocRequest&lt;/code&gt;投递到&lt;code&gt;channel engine.rankerAddDocChannels[shard]&lt;/code&gt;中&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;补充一句：这里&lt;code&gt;shard&lt;/code&gt;号的计算过程如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// 从文本hash得到要分配到的shard
func (engine *Engine) getShard(hash uint32) int {
	return int(hash - hash/uint32(engine.initOptions.NumShards)*uint32(engine.initOptions.NumShards))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为什么不是直接取模呢？&lt;/p&gt;

&lt;h3 id=&#34;索引过程分析-索引器协程处理过程:89e0d5dad305327940f268393030b521&#34;&gt;索引过程分析：索引器协程处理过程&lt;/h3&gt;

&lt;p&gt;首先介绍一下倒排索引表，这是搜索引擎的核心数据结构。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// 索引器
type Indexer struct {
	// 从搜索键到文档列表的反向索引
	// 加了读写锁以保证读写安全
	tableLock struct {
		sync.RWMutex
		table map[string]*KeywordIndices
		docs  map[uint64]bool
	}

	initOptions types.IndexerInitOptions
	initialized bool

	// 这实际上是总文档数的一个近似
	numDocuments uint64

	// 所有被索引文本的总关键词数
	totalTokenLength float32

	// 每个文档的关键词长度
	docTokenLengths map[uint64]float32
}

// 反向索引表的一行，收集了一个搜索键出现的所有文档，按照DocId从小到大排序。
type KeywordIndices struct {
	// 下面的切片是否为空，取决于初始化时IndexType的值
	docIds      []uint64  // 全部类型都有
	frequencies []float32 // IndexType == FrequenciesIndex
	locations   [][]int   // IndexType == LocationsIndex
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;table map[string]*KeywordIndices&lt;/code&gt;这个是核心：一个关键词，对应一个&lt;code&gt;KeywordIndices&lt;/code&gt;结构。该结构的&lt;code&gt;docIds&lt;/code&gt;字段记录了所有包含这个关键词的文档id。
如果 IndexType == FrequenciesIndex ，则同时记录这个关键词在该文档中出现次数。
如果 IndexType == LocationsIndex ，则同时记录这个关键词在该文档中出现的所有位置的起始偏移。&lt;/p&gt;

&lt;p&gt;下面是索引的主函数代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (engine *Engine) indexerAddDocumentWorker(shard int) {
	for {
		request := &amp;lt;-engine.indexerAddDocumentChannels[shard]
		engine.indexers[shard].AddDocument(request.document)
		atomic.AddUint64(&amp;amp;engine.numTokenIndexAdded,
			uint64(len(request.document.Keywords)))
		atomic.AddUint64(&amp;amp;engine.numDocumentsIndexed, 1)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其主要逻辑又封装在&lt;code&gt;func (indexer *Indexer) AddDocument(document *types.DocumentIndex)&lt;/code&gt;函数中实现。其逻辑如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将倒排索引表加锁&lt;/li&gt;
&lt;li&gt;更新文档关键词的长度加在一起的总和&lt;/li&gt;
&lt;li&gt;查找关键词在倒排索引表中是否存在&lt;/li&gt;
&lt;li&gt;如果不存在，则直接加入到&lt;code&gt;table map[string]*KeywordIndices&lt;/code&gt;中&lt;/li&gt;
&lt;li&gt;如果存在&lt;code&gt;KeywordIndices&lt;/code&gt;，则使用二分查找该关键词对应的docId是否已经在&lt;code&gt;KeywordIndices.docIds&lt;/code&gt;中存在。分两种情况：
1) docId存在，则更新原有的数据结构。
2) docId不存在，则插入到&lt;code&gt;KeywordIndices.docIds&lt;/code&gt;数组中，同时保持升序排列。&lt;/li&gt;
&lt;li&gt;更新索引过的文章总数&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;索引过程分析-排序器协程处理过程:89e0d5dad305327940f268393030b521&#34;&gt;索引过程分析：排序器协程处理过程&lt;/h3&gt;

&lt;p&gt;在新索引文档的过程，排序器的主逻辑如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (engine *Engine) rankerAddDocWorker(shard int) {
	for {
		request := &amp;lt;-engine.rankerAddDocChannels[shard]
		engine.rankers[shard].AddDoc(request.docId, request.fields)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进而调用下面的函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// 给某个文档添加评分字段
func (ranker *Ranker) AddDoc(docId uint64, fields interface{}) {
	if ranker.initialized == false {
		log.Fatal(&amp;quot;排序器尚未初始化&amp;quot;)
	}

	ranker.lock.Lock()
	ranker.lock.fields[docId] = fields
	ranker.lock.docs[docId] = true
	ranker.lock.Unlock()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上述函数非常简单，只是将应用层自定义的数据加入到ranker中。&lt;/p&gt;

&lt;p&gt;至此索引过程就完成了。简单来讲就是下面两个过程：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将文档分词，得到一堆关键词&lt;/li&gt;
&lt;li&gt;将 关键词-&amp;gt;docId 的对应关系加入到全局的map中(实际上是分了多个shard)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;搜索过程分析:89e0d5dad305327940f268393030b521&#34;&gt;搜索过程分析&lt;/h2&gt;

&lt;p&gt;下面我们来分析一下搜索的过程。首先构造一个&lt;code&gt;SearchRequest&lt;/code&gt;对象。一般情况下只需提供&lt;code&gt;SearchRequest.Text&lt;/code&gt;即可。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type SearchRequest struct {
	// 搜索的短语（必须是UTF-8格式），会被分词
	// 当值为空字符串时关键词会从下面的Tokens读入
	Text string

	// 关键词（必须是UTF-8格式），当Text不为空时优先使用Text
	// 通常你不需要自己指定关键词，除非你运行自己的分词程序
	Tokens []string

	// 文档标签（必须是UTF-8格式），标签不存在文档文本中，但也属于搜索键的一种
	Labels []string

	// 当不为nil时，仅从这些DocIds包含的键中搜索（忽略值）
	DocIds map[uint64]bool

	// 排序选项
	RankOptions *RankOptions

	// 超时，单位毫秒（千分之一秒）。此值小于等于零时不设超时。
	// 搜索超时的情况下仍有可能返回部分排序结果。
	Timeout int

	// 设为true时仅统计搜索到的文档个数，不返回具体的文档
	CountDocsOnly bool

	// 不排序，对于可在引擎外部（比如客户端）排序情况适用
	// 对返回文档很多的情况打开此选项可以有效节省时间
	Orderless bool
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从本文一开始那段示例代码的搜索语句读起：&lt;code&gt;searcher.Search(types.SearchRequest{Text:&amp;quot;百度中国&amp;quot;})&lt;/code&gt;。进入到 Search 函数内部，其逻辑如下：&lt;/p&gt;

&lt;h3 id=&#34;设置一些搜索选项:89e0d5dad305327940f268393030b521&#34;&gt;设置一些搜索选项&lt;/h3&gt;

&lt;p&gt;例如排序选项&lt;code&gt;RankOptions&lt;/code&gt;, 分数计算条件&lt;code&gt;ScoringCriteria&lt;/code&gt;等等&lt;/p&gt;

&lt;h3 id=&#34;将搜索词进行分词:89e0d5dad305327940f268393030b521&#34;&gt;将搜索词进行分词&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	// 收集关键词
	tokens := []string{}
	if request.Text != &amp;quot;&amp;quot; {
		querySegments := engine.segmenter.Segment([]byte(request.Text))
		for _, s := range querySegments {
			token := s.Token().Text()
			if !engine.stopTokens.IsStopToken(token) {
				tokens = append(tokens, s.Token().Text())
			}
		}
	} else {
		for _, t := range request.Tokens {
			tokens = append(tokens, t)
		}
	}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的&amp;rdquo;百度中国&amp;rdquo;会分词得到两个词：&lt;code&gt;百度&lt;/code&gt; 和&lt;code&gt;中国&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;向索引器发送查找请求:89e0d5dad305327940f268393030b521&#34;&gt;向索引器发送查找请求&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	// 建立排序器返回的通信通道
	rankerReturnChannel := make(
		chan rankerReturnRequest, engine.initOptions.NumShards)

	// 生成查找请求
	lookupRequest := indexerLookupRequest{
		countDocsOnly:       request.CountDocsOnly,
		tokens:              tokens,
		labels:              request.Labels,
		docIds:              request.DocIds,
		options:             rankOptions,
		rankerReturnChannel: rankerReturnChannel,
		orderless:           request.Orderless,
	}

	// 向索引器发送查找请求
	for shard := 0; shard &amp;lt; engine.initOptions.NumShards; shard++ {
		engine.indexerLookupChannels[shard] &amp;lt;- lookupRequest
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里是否可以进行优化？ 1) 只向特定的shard分发请求，避免无谓的indexer查找过程。2) &lt;code&gt;rankerReturnChannel&lt;/code&gt;是否不用每次都创建新的？&lt;/p&gt;

&lt;h3 id=&#34;读取索引器的返回结果然后排序:89e0d5dad305327940f268393030b521&#34;&gt;读取索引器的返回结果然后排序&lt;/h3&gt;

&lt;p&gt;上面已经建立了结果的返回通道&lt;code&gt;rankerReturnChannel&lt;/code&gt;，直接从个&lt;code&gt;channel&lt;/code&gt;中读取返回数据，并加入到数组&lt;code&gt;rankOutput&lt;/code&gt;中。
注意，如果设置了超时，就在超时之前能读取多少就读多少。
然后调用排序算法进行排序。排序算法直接调用Golang自带的&lt;code&gt;sort&lt;/code&gt;包的排序算法。&lt;/p&gt;

&lt;p&gt;下面我们深入到索引器，看看索引器是如何进行搜索的。其核心代码在这里&lt;code&gt;func (engine *Engine) indexerLookupWorker(shard int)&lt;/code&gt;，它的主逻辑是一个死循环，不断的从&lt;code&gt;engine.indexerLookupChannels[shard]&lt;/code&gt;读取搜索请求。&lt;/p&gt;

&lt;p&gt;针对每一个搜索请求，会将请求分发到索引器去，调用&lt;code&gt;func (indexer *Indexer) Lookup(tokens []string, labels []string, docIds map[uint64]bool, countDocsOnly bool) (docs []types.IndexedDocument, numDocs int)&lt;/code&gt;方法。其主要逻辑如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将分词和标签合并在一起进行搜索&lt;/li&gt;
&lt;li&gt;合并搜索到的docId，并进行初步排序，将docId大的排在前面(实际上是认为docId越大，时间越近，时效性越好)&lt;/li&gt;
&lt;li&gt;然后进行排序，BM25算法&lt;/li&gt;
&lt;li&gt;最后返回数据&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;参考文献:89e0d5dad305327940f268393030b521&#34;&gt;参考文献&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/huichen/wukong&#34;&gt;悟空搜索引擎项目源码：https://github.com/huichen/wukong&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/huichen/wukong/blob/master/docs/codelab.md&#34;&gt;悟空引擎入门教程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ayende.com/blog/171745/code-reading-wukong-full-text-search-engine&#34;&gt;Code reading: Wukong full-text search engine&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>应用双缓冲技术完美解决资源数据优雅无损的热加载问题</title>
      <link>http://blog.codeg.cn/2016/01/27/double-buffering/</link>
      <pubDate>Wed, 27 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/2016/01/27/double-buffering/</guid>
      <description>

&lt;h2 id=&#34;简介:dbe09d7cae1f1403ca8285fad9fa9bcc&#34;&gt;简介&lt;/h2&gt;

&lt;p&gt;在一个网络服务器不间断运行过程中，有一些资源数据需要实时更新，例如需要及时更新一份白名单列表，怎么做才能做到优雅无损的更新到服务的进程空间内？这里我们提出一种叫“双缓冲”的技术来解决这种问题。&lt;/p&gt;

&lt;p&gt;这里的双缓冲技术是借鉴了计算机屏幕绘图领域的概念。双缓冲技术绘图即在内存中创建一个与屏幕绘图区域一致的对象，先将图形绘制到内存中的这个对象上，再一次性将这个对象上的图形拷贝到屏幕上，这样能大大加快绘图的速度。&lt;/p&gt;

&lt;h3 id=&#34;问题抽象:dbe09d7cae1f1403ca8285fad9fa9bcc&#34;&gt;问题抽象&lt;/h3&gt;

&lt;p&gt;假设我们有一个查询服务，为了方便描述，我们将数据加密传输等一些不必要的细节都省去后，请求报文可以抽象成两个参数：一个是id，用来唯一标识一台设备（例如手机或电脑）；另一个查询主体query。服务端业务逻辑是通过query查询数据库/NoSQL等数据引擎然后返回相应的数据，同时记录一条请求日志。&lt;/p&gt;

&lt;p&gt;用Golang来实现这个逻辑如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;net/http&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;fmt&amp;quot;
)

func Query(r *http.Request) string {
	id := r.FormValue(&amp;quot;id&amp;quot;)
	query := r.FormValue(&amp;quot;query&amp;quot;)

	//参数合法性检查

	//具体的业务逻辑，查询数据库/NoSQL等数据引擎，然后做逻辑计算，然后合并结果
	//这里简单抽象，直接返回欢迎语
	result := fmt.Sprintf(&amp;quot;hello, %v&amp;quot;, id)

	// 记录一条查询日志，用于离线统计和分析
	log.Printf(&amp;quot;&amp;lt;id=%v&amp;gt;&amp;lt;query=%v&amp;gt;&amp;lt;result=%v&amp;gt;&amp;lt;ip=%v&amp;gt;&amp;quot;, id, query, result, r.RemoteAddr)

	return result
}

func Handler(w http.ResponseWriter, r *http.Request) {
	r.ParseForm()
	result := Query(r)
	w.Write([]byte(result))
}

func main() {
	http.HandleFunc(&amp;quot;/q&amp;quot;, Handler)
	hostname, _ := os.Hostname()
	log.Printf(&amp;quot;start http://%s:8091/q&amp;quot;, hostname)
	log.Fatal(http.ListenAndServe(&amp;quot;:8091&amp;quot;, nil))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;服务上线一段时间后，通过日志分析发现有一些id发起的请求异常，每天的请求量远远高于其他id，我们有理由怀疑这些请求是竞争对手在抓我们的数据。这个时候就开始进入攻防阶段了。&lt;/p&gt;

&lt;p&gt;有几种攻防策略可供选择：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;直接封IP，这种策略有可能会误杀一些正常用户。&lt;/li&gt;
&lt;li&gt;将id加入黑名单&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;假设我们将策略1放到前端接入服务处(例如Nginx)进行拦截，策略2在我们自己的业务逻辑中实现，即在Query函数中加入对id的判断即可。现在的完整代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;net/http&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;bytes&amp;quot;
	&amp;quot;strings&amp;quot;
	&amp;quot;io&amp;quot;
)

var blackIDs map[string]int
func LoadBlackIDs(filepath string) error {
	// 加载黑名单列表文件，每行一个
	b, err := ioutil.ReadFile(filepath)
	if err != nil {
		return err
	}
	r := bytes.NewBuffer(b)
	for {
		id, err := r.ReadString(&#39;\n&#39;)
		if err == io.EOF || err == nil {
			id = strings.TrimSpace(id)
			if len(id) &amp;gt; 0 {
				blackIDs[id] = 1
			}
		}

		if err != nil {
			break
		}
	}

	return nil
}

func IsBlackID(id string) bool {
	_, exist := blackIDs[id]
	return exist
}

func Query(r *http.Request) (string, error) {
	id := r.FormValue(&amp;quot;id&amp;quot;)
	query := r.FormValue(&amp;quot;query&amp;quot;)

	//参数合法性检查

	if IsBlackID(id) {
		return &amp;quot;ERROR&amp;quot;, fmt.Errorf(&amp;quot;ERROR id&amp;quot;)
	}

	//具体的业务逻辑，查询数据库/NoSQL等数据引擎，然后做逻辑计算，然后合并结果
	//这里简单抽象，直接返回欢迎语
	result := fmt.Sprintf(&amp;quot;hello, %v&amp;quot;, id)

	// 记录一条查询日志，用于离线统计和分析
	log.Printf(&amp;quot;&amp;lt;id=%v&amp;gt;&amp;lt;query=%v&amp;gt;&amp;lt;result=%v&amp;gt;&amp;lt;ip=%v&amp;gt;&amp;quot;, id, query, result, r.RemoteAddr)

	return result, nil
}

func Handler(w http.ResponseWriter, r *http.Request) {
	r.ParseForm()
	result, err := Query(r)
	if err == nil {
		w.Write([]byte(result))
	} else {
		w.WriteHeader(403)
		w.Write([]byte(result))
	}
}

func main() {
	blackIDs = make(map[string]int)
	if len(os.Args) == 2 {
		err := LoadBlackIDs(os.Args[1])
		if err != nil {
			panic(err)
		}
	}

	http.HandleFunc(&amp;quot;/q&amp;quot;, Handler)
	hostname, _ := os.Hostname()
	log.Printf(&amp;quot;start http://%s:8091/q&amp;quot;, hostname)
	log.Fatal(http.ListenAndServe(&amp;quot;:8091&amp;quot;, nil))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过上述努力，终于将一些异常请求屏蔽掉了，一看时间都凌晨了，恩，好好回家碎个叫，累死哥了。&lt;/p&gt;

&lt;h3 id=&#34;解决思路:dbe09d7cae1f1403ca8285fad9fa9bcc&#34;&gt;解决思路&lt;/h3&gt;

&lt;p&gt;又过了一些日子，产品妹子还是找过来了，说我们的最新数据又被竞争对手抓走了，肿么回事？
我们只能做一个离线流程将恶意id实时过滤出来，然后及时反馈到在线服务中去，
一开始想到可以通过重启进程的方式来加载这份black_id.txt，这就要求我们的程序对reload要做到足够优雅，
例如不能丢请求、reload过程中要足够平滑，短时间做到这一点还有些困难。另外，整个程序reload过程所消耗的CPU/IO资源较多，例如一些不需更新的资源也需要reload。
如果能做到按需加载就更好了，即：哪个资源有变化，我们就只加载那个资源。
然后我们就想到了本文所提到的双缓冲技术。&lt;/p&gt;

&lt;p&gt;这里的双缓冲技术是指对black_id.txt文件的加载过程是在后台独立加载，等加载完毕之后，再与当前正在使用的对象直接交换一下，即可完成新文件的加载。
这里有几个细节需要讨论一下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;black_id.txt在内存中是一个map结构，有人说，等有更新时，直接将增量更新进map即可，这就需要对该map结构上锁，且所有用到的地方都加锁，锁粒度有点粗&lt;/li&gt;
&lt;li&gt;一个简单直接的办法是对black_id.txt整体重新生成一个新的map结构，使用的时候直接拿到这个map的指针替换掉原来的指针即可&lt;/li&gt;
&lt;li&gt;新老替换后，老的资源什么释放？在Golang中，一般情况下可以通过其自身的GC来释放即可。但有时候，有一些资源是需要我们自己主动释放的，GC这一点做不到，例如通过CGO方式嵌入进来的C扩展对象的释放工作。这里我们通过引用计数技术来解决。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;双缓冲技术golang实现:dbe09d7cae1f1403ca8285fad9fa9bcc&#34;&gt;双缓冲技术Golang实现&lt;/h3&gt;

&lt;p&gt;直接上代码。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (
	&amp;quot;sync&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;crypto/md5&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;time&amp;quot;
	&amp;quot;sync/atomic&amp;quot;
)

type DoubleBufferingTarget interface {
	Initialize(conf string) bool // 初始化，继承类可以在此做一些初始化的工作
	Close() // 继承类如果在Initialize函数中申请了一些资源，可以在这里将这些资源进行回收
}

type DoubleBufferingTargetCreator func() DoubleBufferingTarget

type DoubleBufferingTargetRef struct {
	Target DoubleBufferingTarget
	ref    *int32
}

type DoubleBuffering struct {
	creator         DoubleBufferingTargetCreator

	mutex           sync.Mutex
	refTarget       DoubleBufferingTargetRef

	reloadTimestamp int64
	md5h            string
}


func newDoubleBuffering(f DoubleBufferingTargetCreator) *DoubleBuffering {
	d := new(DoubleBuffering)
	d.creator = f
	d.reloadTimestamp = 0
	return d
}

func (d *DoubleBuffering) reload(conf string) bool {
	t := d.creator()
	if t.Initialize(conf) == false {
		return false
	}

	content, err := ioutil.ReadFile(conf)
	if err != nil {
		content = []byte(conf)
	}
	d.md5h = fmt.Sprint(&amp;quot;%x&amp;quot;, md5.Sum(content))
	d.reloadTimestamp = time.Now().Unix()

	d.mutex.Lock()
	defer d.mutex.Unlock()
	d.refTarget.Release() // 将老对象释放掉

	d.refTarget.Target = t
	d.refTarget.ref = new(int32)
	*d.refTarget.ref = 1 // 初始设置为1，由DoubleBuffering代为管理

	return true
}

// ReloadTimestamp return the latest timestamp when the DoubleBuffering reloaded at the last time
func (d *DoubleBuffering) ReloadTimestamp() int64 {
	return d.reloadTimestamp
}

// LatestConfMD5 return the latest config&#39;s md5
func (d *DoubleBuffering) LatestConfMD5() string {
	return d.md5h
}

// Get return the target this DoubleBuffering manipulated.
// You should call DoubleBufferingTargetRef.Release() function after you have used it.
func (d *DoubleBuffering) Get() DoubleBufferingTargetRef {
	d.mutex.Lock()
	defer d.mutex.Unlock()
	atomic.AddInt32(d.refTarget.ref, 1)
	return d.refTarget
}

func (d DoubleBufferingTargetRef) Release() {
	if d.ref != nil &amp;amp;&amp;amp; atomic.AddInt32(d.ref, -1) == 0 {
		d.Target.Close()
	}
}

func (d DoubleBufferingTargetRef) Ref() int32 {
	if d.ref != nil {
		return *d.ref
	}

	return 0
}

type DoubleBufferingMap map[string/*name*/]*DoubleBuffering
type DoubleBufferingManager struct {
	targets DoubleBufferingMap
	mutex sync.Mutex
}

func NewDoubleBufferingManager() *DoubleBufferingManager {
	m := new(DoubleBufferingManager)
	m.targets = make(DoubleBufferingMap)
	return m
}

func (m *DoubleBufferingManager) Add(name string, conf string, f DoubleBufferingTargetCreator) bool {
	d := newDoubleBuffering(f)
	if d.reload(conf) {
		m.targets[name] = d
		return true
	}

	return false
}

func (m *DoubleBufferingManager) Get(name string) *DoubleBuffering {
	m.mutex.Lock()
	defer m.mutex.Unlock()
	if t, ok := m.targets[name]; ok {
		return t
	}

	//panic(&amp;quot;cannot find this kind of DoubleBuffering&amp;quot;)
	return nil
}

func (m *DoubleBufferingManager) Reload(name, conf string) bool {
	d := m.Get(name)
	if d == nil {
		return false
	}

	return d.reload(conf)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用doublebuffering改造最开始那个抽象问题:dbe09d7cae1f1403ca8285fad9fa9bcc&#34;&gt;使用DoubleBuffering改造最开始那个抽象问题&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;net/http&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;io/ioutil&amp;quot;
	&amp;quot;bytes&amp;quot;
	&amp;quot;strings&amp;quot;
	&amp;quot;io&amp;quot;
)

type BlackIDDict struct {
	blackIDs map[string]int
}

func NewBlackIDDict() DoubleBufferingTarget {
	d := &amp;amp;BlackIDDict{
		blackIDs: make(map[string]int),
	}
	return d
}

var dbm *DoubleBufferingManager

func (d *BlackIDDict) Initialize(conf string) bool {
	filepath := conf

	// 加载黑名单列表文件，每行一个
	b, err := ioutil.ReadFile(filepath)
	if err != nil {
		return false
	}
	r := bytes.NewBuffer(b)
	for {
		id, err := r.ReadString(&#39;\n&#39;)
		if err == io.EOF || err == nil {
			id = strings.TrimSpace(id)
			if len(id) &amp;gt; 0 {
				d.blackIDs[id] = 1
			}
		}

		if err != nil {
			break
		}
	}

	return true
}

func (d *BlackIDDict) Close() {
	// 在这里做一些资源释放工作
	// 当前这个例子没有资源需要我们手工释放
}

func (d *BlackIDDict) IsBlackID(id string) bool {
	_, exist := d.blackIDs[id]
	return exist
}

func Query(r *http.Request) (string, error) {
	id := r.FormValue(&amp;quot;id&amp;quot;)
	query := r.FormValue(&amp;quot;query&amp;quot;)

	//TODO 参数合法性检查

	d := dbm.Get(&amp;quot;black_id&amp;quot;)
	tg := d.Get()
	defer tg.Release()
	dict := tg.Target.(*BlackIDDict)  // 转换为具体的Dict对象
	if dict == nil {
		return &amp;quot;&amp;quot;, fmt.Errorf(&amp;quot;ERROR, Convert DoubleBufferingTarget to Dict failed&amp;quot;)
	}

	if dict.IsBlackID(id) {
		return &amp;quot;ERROR&amp;quot;, fmt.Errorf(&amp;quot;ERROR id&amp;quot;)
	}

	//具体的业务逻辑，查询数据库/NoSQL等数据引擎，然后做逻辑计算，然后合并结果
	//这里简单抽象，直接返回欢迎语
	result := fmt.Sprintf(&amp;quot;hello, %v&amp;quot;, id)

	// 记录一条查询日志，用于离线统计和分析
	log.Printf(&amp;quot;&amp;lt;id=%v&amp;gt;&amp;lt;query=%v&amp;gt;&amp;lt;result=%v&amp;gt;&amp;lt;ip=%v&amp;gt;&amp;quot;, id, query, result, r.RemoteAddr)

	return result, nil
}

func Handler(w http.ResponseWriter, r *http.Request) {
	r.ParseForm()
	result, err := Query(r)
	if err == nil {
		w.Write([]byte(result))
	} else {
		w.WriteHeader(403)
		w.Write([]byte(result))
	}
}

func Reload(w http.ResponseWriter, r *http.Request) {
	// 这里简化处理，直接重新加载black_id。如果有多个，可以从url参数中获取资源名称
	if dbm.Reload(&amp;quot;black_id&amp;quot;, os.Args[1]) {
		w.Write([]byte(&amp;quot;OK&amp;quot;))
	} else {
		w.Write([]byte(&amp;quot;FAILED&amp;quot;))
	}
}

func main() {
	if len(os.Args) != 2 {
		panic(&amp;quot;Not specify black_id.txt&amp;quot;)
	}

	dbm = NewDoubleBufferingManager()
	rc := dbm.Add(&amp;quot;black_id&amp;quot;, os.Args[1], NewBlackIDDict)
	if rc == false {
		panic(&amp;quot;black_id initialize failed&amp;quot;)
	}

	http.HandleFunc(&amp;quot;/q&amp;quot;, Handler)
	http.HandleFunc(&amp;quot;/admin/reload&amp;quot;, Reload) // 管理接口，用于重新加载black_id.txt。如果有多个这种资源，可以增加一些参数来说区分不同的资源
	hostname, _ := os.Hostname()
	log.Printf(&amp;quot;start http://%s:8091/q&amp;quot;, hostname)
	log.Fatal(http.ListenAndServe(&amp;quot;:8091&amp;quot;, nil))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;程序启动之后，使用black_id.txt里面的id请求时，都会返回403，如果有新增的black_id，我们也加入到black_id.txt文件中，然后调用 &lt;code&gt;/admin/reload&lt;/code&gt; 接口使之生效即可。&lt;/p&gt;

&lt;h3 id=&#34;c-版本实现:dbe09d7cae1f1403ca8285fad9fa9bcc&#34;&gt;C++版本实现&lt;/h3&gt;

&lt;p&gt;//TODO&lt;/p&gt;

&lt;h2 id=&#34;参考文献:dbe09d7cae1f1403ca8285fad9fa9bcc&#34;&gt;参考文献&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://baike.haosou.com/doc/302938-320692.html&#34;&gt;双缓冲技术介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/zieckey/go-doublebuffering&#34;&gt;Golang实现的示例源码在这里 https://github.com/zieckey/go-doublebuffering&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>serf介绍</title>
      <link>http://blog.codeg.cn/2015/12/20/serf/</link>
      <pubDate>Sun, 20 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/2015/12/20/serf/</guid>
      <description>

&lt;h2 id=&#34;简介:0944400516c0fa656ac8b2fdb8ad1608&#34;&gt;简介&lt;/h2&gt;

&lt;p&gt;Serf是一个无中心化的服务调度和服务发现工具。它容错性极好、无中心化设计、没有单点故障。Serf是建立在Gossip协议之上的，Gossip协议就是为无中心化通信而设计的。为了让一个新节点加入Serf集群，只需要知道集群中的任意一个节点即可，一旦新节点加入进来，它将获得集群中所有的成员信息。Gossip协议让Serf的配置和启动变得非常容易。&lt;/p&gt;

&lt;h2 id=&#34;如何使用:0944400516c0fa656ac8b2fdb8ad1608&#34;&gt;如何使用&lt;/h2&gt;

&lt;p&gt;在官方网站 &lt;a href=&#34;https://www.serfdom.io/downloads.html&#34;&gt;https://www.serfdom.io/downloads.html&lt;/a&gt; 下载合适的版本。&lt;/p&gt;

&lt;h3 id=&#34;简单使用:0944400516c0fa656ac8b2fdb8ad1608&#34;&gt;简单使用&lt;/h3&gt;

&lt;p&gt;新建一个事件处理器脚本，例如 handler.sh ：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash
if [ &amp;quot;${SERF_USER_EVENT}&amp;quot; = &amp;quot;memresponse&amp;quot; ]; then
    cat &amp;gt;&amp;gt; /tmp/mem.txt
    echo &amp;quot;\n&amp;quot; &amp;gt;&amp;gt; /tmp/mem.txt
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再启动 serf 服务，绑定&lt;code&gt;handler.sh&lt;/code&gt;为默认的事件处理器：
    ./serf agent -bind=133.130.106.57:5001 -rpc-addr=133.130.106.57:7373   -log-level=debug -event-handler=./handler.sh&lt;/p&gt;

&lt;p&gt;再再再另一个console窗口利用serf命令发送一个事件到之前启动的serf：
    ./serf event -rpc-addr=133.130.106.57:7373 memresponse xcxx&lt;/p&gt;

&lt;p&gt;我们可以到serf服务的窗口输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$  ./serf agent -bind=133.130.106.57:5001 -rpc-addr=133.130.106.57:7373   -log-level=debug -event-handler=./handler.sh
==&amp;gt; Starting Serf agent...
==&amp;gt; Starting Serf agent RPC...
==&amp;gt; Serf agent running!
         Node name: &#39;133-130-106-57&#39;
         Bind addr: &#39;133.130.106.57:5001&#39;
          RPC addr: &#39;133.130.106.57:7373&#39;
         Encrypted: false
          Snapshot: false
           Profile: lan

==&amp;gt; Log data will now stream in as it occurs:

    2015/12/20 10:06:03 [INFO] agent: Serf agent starting
    2015/12/20 10:06:03 [WARN] memberlist: Binding to public address without encryption!
    2015/12/20 10:06:03 [INFO] serf: EventMemberJoin: 133-130-106-57 133.130.106.57
    2015/12/20 10:06:04 [INFO] agent: Received event: member-join
    2015/12/20 10:06:04 [DEBUG] agent: Event &#39;member-join&#39; script output: 
    2015/12/20 10:06:13 [INFO] agent.ipc: Accepted client: 133.130.106.57:34964
    2015/12/20 10:06:13 [DEBUG] agent: Requesting user event send: memresponse. Coalesced: true. Payload: &amp;quot;xcxx&amp;quot;
    2015/12/20 10:06:14 [INFO] agent: Received event: user-event: memresponse
    2015/12/20 10:06:14 [DEBUG] agent: Event &#39;user&#39; script output: 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们去看看 &lt;code&gt;/tmp/mem.txt&lt;/code&gt; 文件的内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;xcxx
\n
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;构建serf集群:0944400516c0fa656ac8b2fdb8ad1608&#34;&gt;构建serf集群&lt;/h3&gt;

&lt;h2 id=&#34;参考文献:0944400516c0fa656ac8b2fdb8ad1608&#34;&gt;参考文献&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.serfdom.io&#34;&gt;官方网站 https://www.serfdom.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-set-up-a-serf-cluster-on-several-ubuntu-vps&#34;&gt;https://www.digitalocean.com/community/tutorials/how-to-set-up-a-serf-cluster-on-several-ubuntu-vps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://iankent.uk/blog/getting-started-with-hashicorp-serf/&#34;&gt;http://iankent.uk/blog/getting-started-with-hashicorp-serf/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>godotenv介绍</title>
      <link>http://blog.codeg.cn/2015/12/15/godotenv/</link>
      <pubDate>Tue, 15 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/2015/12/15/godotenv/</guid>
      <description>

&lt;h2 id=&#34;简介:a2f6952cdcca5db49437e97fa612c308&#34;&gt;简介&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;godotenv&lt;/code&gt;是ruby社区的&lt;code&gt;dotenv&lt;/code&gt;的Golang移植版本。该库会解析 &lt;strong&gt;.env&lt;/strong&gt; 文件，该文件是一个典型的INI格式的文件，类似于下面：&lt;/p&gt;

&lt;p&gt;SOME_ENV_VAR=somevalue&lt;/p&gt;

&lt;p&gt;然后在你的代码中调用 &lt;code&gt;godotenv.Load()&lt;/code&gt; 即可解析并将相应的Key/Value对都放到环境变量中。&lt;/p&gt;

&lt;p&gt;例如可以通过 &lt;code&gt;os.Getenv(&amp;quot;SOME_ENV_VAR&amp;quot;)&lt;/code&gt; 获取。&lt;/p&gt;

&lt;h2 id=&#34;参考文献:a2f6952cdcca5db49437e97fa612c308&#34;&gt;参考文献&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bkeepers/dotenv&#34;&gt;dotenv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/joho/godotenv&#34;&gt;godotenv&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>nsq介绍及源码阅读</title>
      <link>http://blog.codeg.cn/2015/10/22/nsq/</link>
      <pubDate>Thu, 22 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/2015/10/22/nsq/</guid>
      <description>

&lt;h2 id=&#34;简介:d95215f25ddc5c9409dc591338ad4840&#34;&gt;简介&lt;/h2&gt;

&lt;h2 id=&#34;nsq客户端逻辑:d95215f25ddc5c9409dc591338ad4840&#34;&gt;nsq客户端逻辑&lt;/h2&gt;

&lt;h3 id=&#34;nsq消费者:d95215f25ddc5c9409dc591338ad4840&#34;&gt;nsq消费者&lt;/h3&gt;

&lt;p&gt;主要请参考&lt;code&gt;nsq_tail&lt;/code&gt;代码。消息处理代码为&lt;code&gt;func (c *Conn) readLoop()&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;TCP消息流的二进制结构请参考官方文档：&lt;a href=&#34;http://nsq.io/clients/tcp_protocol_spec.html&#34;&gt;http://nsq.io/clients/tcp_protocol_spec.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;nsqd内部处理逻辑:d95215f25ddc5c9409dc591338ad4840&#34;&gt;nsqd内部处理逻辑&lt;/h3&gt;

&lt;h4 id=&#34;与nsqlookupd交互:d95215f25ddc5c9409dc591338ad4840&#34;&gt;与nsqlookupd交互&lt;/h4&gt;

&lt;p&gt;代码调用路径如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	nsqd.Main()
	n.waitGroup.Wrap(func() { n.lookupLoop() })
	func (n *NSQD) lookupLoop() : 91行： case val := &amp;lt;-n.notifyChan:
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;消息分发:d95215f25ddc5c9409dc591338ad4840&#34;&gt;消息分发&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;func (t *Topic) messagePump()&lt;/code&gt; 这里进行消息的分发，直接将该topic下的消息推送给所有的channel上。&lt;/p&gt;

&lt;h4 id=&#34;消息id:d95215f25ddc5c9409dc591338ad4840&#34;&gt;消息ID&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;func (n *NSQD) idPump()&lt;/code&gt; 这里生成新的消息ID，然后放入到 &lt;code&gt;n.idChan&lt;/code&gt; 中。64位int64的guid生成算法参考&lt;a href=&#34;https://github.com/bmizerany/noeqd&#34;&gt;https://github.com/bmizerany/noeqd&lt;/a&gt;，主要部分解释如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;time - 41位 (当前毫秒数，一共69年)
配置好的机器ID - 10 bits - 一共支持1024个机器
顺序好 - 12 bits - 每个机器在同一毫秒内一共支持4096个
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;pub接口:d95215f25ddc5c9409dc591338ad4840&#34;&gt;pub接口&lt;/h4&gt;

&lt;p&gt;发布一条消息到NSQ消息队列中。代码路径 &lt;code&gt;func (s *httpServer) doPUB(w http.ResponseWriter, req *http.Request, ps httprouter.Params) (interface{}, error)&lt;/code&gt; 。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;判断消息长度是否超过限制&lt;/li&gt;
&lt;li&gt;获取topic名称&lt;/li&gt;
&lt;li&gt;根据topic名称，获取&lt;code&gt;Topic&lt;/code&gt;对象，最终会调用到这里：&lt;code&gt;func (n *NSQD) GetTopic(topicName string) *Topic&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;如果topic存在，直接返回&lt;code&gt;Topic&lt;/code&gt;对象&lt;/li&gt;
&lt;li&gt;如果topic不存在，就创建一个:&lt;code&gt;func NewTopic(topicName string, ctx *context, deleteCallback func(*Topic)) *Topic&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;创建&lt;code&gt;Topic&lt;/code&gt;之后，询问&lt;code&gt;lookupd&lt;/code&gt;，获取所有关注这个topic的channel列表，然后获取或创建这些&lt;code&gt;Channel&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;创建一个新的Message：&lt;code&gt;msg := NewMessage(&amp;lt;-s.ctx.nsqd.idChan, body)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;将该消息放到&lt;code&gt;Topic&lt;/code&gt;上：&lt;code&gt;err = topic.PutMessage(msg)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;参考文献:d95215f25ddc5c9409dc591338ad4840&#34;&gt;参考文献&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://nsq.io/overview/design.html&#34;&gt;官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://wiki.jikexueyuan.com/project/nsq-guide/&#34;&gt;NSQ指南中文翻译&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>ansible简介</title>
      <link>http://blog.codeg.cn/2015/10/08/ansible/</link>
      <pubDate>Thu, 08 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>http://blog.codeg.cn/2015/10/08/ansible/</guid>
      <description>

&lt;h2 id=&#34;简介:f188025e536204472e8b7261593031f9&#34;&gt;简介&lt;/h2&gt;

&lt;p&gt;ansible是新出现的自动化运维工具，基于Python开发，集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。ansible是基于模块工作的，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。主要包括：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;连接插件connection plugins：负责和被监控端实现通信；&lt;/li&gt;
&lt;li&gt;host inventory：指定操作的主机，是一个配置文件里面定义监控的主机；&lt;/li&gt;
&lt;li&gt;各种模块核心模块、command模块、自定义模块；&lt;/li&gt;
&lt;li&gt;借助于插件完成记录日志邮件等功能；&lt;/li&gt;
&lt;li&gt;playbook：剧本执行多个任务时，非必需可以让节点一次性运行多个任务。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;在centos上安装:f188025e536204472e8b7261593031f9&#34;&gt;在centos上安装&lt;/h2&gt;

&lt;p&gt;直接使用yum安装即可： &lt;code&gt;sudo yum install ansible&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;简单使用:f188025e536204472e8b7261593031f9&#34;&gt;简单使用&lt;/h2&gt;

&lt;p&gt;其默认的配置路径： &lt;code&gt;/etc/ansible/ansible.cfg&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;为了避免SHH key host检查，可以将下面配置项打开：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;host_key_checking = False
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外，为避免一些依赖（依赖目标机器上的软件环境），可以使用 &lt;code&gt;-m raw&lt;/code&gt; 参数，例如下面是没有加这个参数时会出错：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ansible builddev -m shell -a &amp;quot;uname -a&amp;quot; -k       
SSH password: 
10.16.28.17 | FAILED &amp;gt;&amp;gt; {
    &amp;quot;failed&amp;quot;: true, 
    &amp;quot;msg&amp;quot;: &amp;quot;/usr/bin/python: not found\n&amp;quot;, 
    &amp;quot;parsed&amp;quot;: false
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;加上这个参数就没有问题： &lt;code&gt;ansible builddev -m shell -m raw -a &amp;quot;uname -a&amp;quot; -k&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;修改配置文件:f188025e536204472e8b7261593031f9&#34;&gt;修改配置文件&lt;/h3&gt;

&lt;p&gt;ansible使用配置文件 &lt;code&gt;/etc/ansible/hosts&lt;/code&gt; 。其格式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# This is the default ansible &#39;hosts&#39; file.
#
# It should live in /etc/ansible/hosts
#
#   - Comments begin with the &#39;#&#39; character
#   - Blank lines are ignored
#   - Groups of hosts are delimited by [header] elements
#   - You can enter hostnames or ip addresses
#   - A hostname/ip can be a member of multiple groups

# Ex 1: Ungrouped hosts, specify before any group headers.

green.example.com
blue.example.com
192.168.100.1
192.168.100.10

# Ex 2: A collection of hosts belonging to the &#39;webservers&#39; group

[webservers]
alpha.example.org
beta.example.org
192.168.1.100
192.168.1.110

# If you have multiple hosts following a pattern you can specify
# them like this:

www[001:006].example.com

# Ex 3: A collection of database servers in the &#39;dbservers&#39; group

[dbservers]

db01.intranet.mydomain.net
db02.intranet.mydomain.net
10.25.1.56
10.25.1.57

# Here&#39;s another example of host ranges, this time there are no
# leading 0s:

db-[99:101]-node.example.com
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们编辑这个文件，删除原来所有的配置，然后增加一个group，最终完整文件内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[build]
10.16.29.179
10.16.28.17
10.16.28.18
10.16.29.88
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用:f188025e536204472e8b7261593031f9&#34;&gt;使用&lt;/h3&gt;

&lt;h4 id=&#34;示例1-ansible-build-a-date-k:f188025e536204472e8b7261593031f9&#34;&gt;示例1：ansible build -a date -k&lt;/h4&gt;

&lt;p&gt;该命令标示针对&lt;code&gt;build&lt;/code&gt;这一组机器，执行&lt;code&gt;date&lt;/code&gt;命令，&lt;code&gt;-k&lt;/code&gt;标示要使用ssh时提示密码输入符，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[codeg@build ~]$ ansible build -a date -k       
SSH password: 

paramiko: The authenticity of host &#39;10.16.29.88&#39; can&#39;t be established.
The ssh-rsa key fingerprint is 3151f8e35301c476af609c3bb31b5e37.
Are you sure you want to continue connecting (yes/no)?
yes
10.16.28.18 | success | rc=0 &amp;gt;&amp;gt;
Thu Oct  8 11:43:49 CST 2015

10.16.29.179 | success | rc=0 &amp;gt;&amp;gt;
Thu Oct  8 11:50:14 CST 2015

10.16.28.17 | success | rc=0 &amp;gt;&amp;gt;
Thu Oct  8 11:50:14 CST 2015

10.16.29.88 | success | rc=0 &amp;gt;&amp;gt;
Thu Oct  8 11:50:18 CST 2015
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;示例2-执行复杂的命令-ansible-build-m-shell-a-ls-l-head-1-k:f188025e536204472e8b7261593031f9&#34;&gt;示例2，执行复杂的命令：ansible build -m shell -a &amp;ldquo;ls -l | head -1&amp;rdquo; -k&lt;/h4&gt;

&lt;p&gt;使用shell模块，表明是执行shell指令。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ansible build -m shell -a &amp;quot;ls -l | head -1&amp;quot; -k
SSH password: 
10.16.28.17 | success | rc=0 &amp;gt;&amp;gt;
total 454360

10.16.28.18 | success | rc=0 &amp;gt;&amp;gt;
total 33288

10.16.29.179 | success | rc=0 &amp;gt;&amp;gt;
total 87776

10.16.29.88 | success | rc=0 &amp;gt;&amp;gt;
total 469384ls: write error: Broken pipe
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;示例3-文件拷贝-ansible-build-m-copy-a-src-a-sh-dest-tmp-abcx-sh-k:f188025e536204472e8b7261593031f9&#34;&gt;示例3，文件拷贝：ansible build -m copy -a &amp;ldquo;src=a.sh dest=/tmp/abcx.sh&amp;rdquo; -k&lt;/h4&gt;

&lt;p&gt;使用&lt;code&gt;copy&lt;/code&gt;模块来传输文件，通过src/dest两个参数来指定原始文件和目标机的目的地址。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ansible build -m copy -a &amp;quot;src=a.sh dest=/tmp/abcx.sh&amp;quot; -k  
SSH password: 
10.16.28.18 | success &amp;gt;&amp;gt; {
    &amp;quot;changed&amp;quot;: true, 
    &amp;quot;checksum&amp;quot;: &amp;quot;b9da991c935ccdda2231e2a3704ef943035dd4d4&amp;quot;, 
    &amp;quot;dest&amp;quot;: &amp;quot;/tmp/abcx.sh&amp;quot;, 
    &amp;quot;gid&amp;quot;: 3534, 
    &amp;quot;group&amp;quot;: &amp;quot;codeg&amp;quot;, 
    &amp;quot;md5sum&amp;quot;: &amp;quot;1506d51353f96a582b86891999e63091&amp;quot;, 
    &amp;quot;mode&amp;quot;: &amp;quot;0664&amp;quot;, 
    &amp;quot;owner&amp;quot;: &amp;quot;codeg&amp;quot;, 
    &amp;quot;size&amp;quot;: 61, 
    &amp;quot;src&amp;quot;: &amp;quot;/home/codeg/.ansible/tmp/ansible-tmp-1444292722.63-246642726358339/source&amp;quot;, 
    &amp;quot;state&amp;quot;: &amp;quot;file&amp;quot;, 
    &amp;quot;uid&amp;quot;: 3534
}

10.16.28.17 | success &amp;gt;&amp;gt; {
    &amp;quot;changed&amp;quot;: true, 
    &amp;quot;checksum&amp;quot;: &amp;quot;b9da991c935ccdda2231e2a3704ef943035dd4d4&amp;quot;, 
    &amp;quot;dest&amp;quot;: &amp;quot;/tmp/abcx.sh&amp;quot;, 
    &amp;quot;gid&amp;quot;: 3534, 
    &amp;quot;group&amp;quot;: &amp;quot;codeg&amp;quot;, 
    &amp;quot;md5sum&amp;quot;: &amp;quot;1506d51353f96a582b86891999e63091&amp;quot;, 
    &amp;quot;mode&amp;quot;: &amp;quot;0664&amp;quot;, 
    &amp;quot;owner&amp;quot;: &amp;quot;codeg&amp;quot;, 
    &amp;quot;size&amp;quot;: 61, 
    &amp;quot;src&amp;quot;: &amp;quot;/home/codeg/.ansible/tmp/ansible-tmp-1444292722.67-256074204427798/source&amp;quot;, 
    &amp;quot;state&amp;quot;: &amp;quot;file&amp;quot;, 
    &amp;quot;uid&amp;quot;: 3534
}

10.16.29.88 | success &amp;gt;&amp;gt; {
    &amp;quot;changed&amp;quot;: true, 
    &amp;quot;checksum&amp;quot;: &amp;quot;b9da991c935ccdda2231e2a3704ef943035dd4d4&amp;quot;, 
    &amp;quot;dest&amp;quot;: &amp;quot;/tmp/abcx.sh&amp;quot;, 
    &amp;quot;gid&amp;quot;: 3534, 
    &amp;quot;group&amp;quot;: &amp;quot;codeg&amp;quot;, 
    &amp;quot;md5sum&amp;quot;: &amp;quot;1506d51353f96a582b86891999e63091&amp;quot;, 
    &amp;quot;mode&amp;quot;: &amp;quot;0664&amp;quot;, 
    &amp;quot;owner&amp;quot;: &amp;quot;codeg&amp;quot;, 
    &amp;quot;size&amp;quot;: 61, 
    &amp;quot;src&amp;quot;: &amp;quot;/home/codeg/.ansible/tmp/ansible-tmp-1444292722.64-195326527082374/source&amp;quot;, 
    &amp;quot;state&amp;quot;: &amp;quot;file&amp;quot;, 
    &amp;quot;uid&amp;quot;: 3534
}

10.16.29.179 | success &amp;gt;&amp;gt; {
    &amp;quot;changed&amp;quot;: true, 
    &amp;quot;checksum&amp;quot;: &amp;quot;b9da991c935ccdda2231e2a3704ef943035dd4d4&amp;quot;, 
    &amp;quot;dest&amp;quot;: &amp;quot;/tmp/abcx.sh&amp;quot;, 
    &amp;quot;gid&amp;quot;: 3534, 
    &amp;quot;group&amp;quot;: &amp;quot;codeg&amp;quot;, 
    &amp;quot;md5sum&amp;quot;: &amp;quot;1506d51353f96a582b86891999e63091&amp;quot;, 
    &amp;quot;mode&amp;quot;: &amp;quot;0664&amp;quot;, 
    &amp;quot;owner&amp;quot;: &amp;quot;codeg&amp;quot;, 
    &amp;quot;size&amp;quot;: 61, 
    &amp;quot;src&amp;quot;: &amp;quot;/home/codeg/.ansible/tmp/ansible-tmp-1444292722.68-230895291500491/source&amp;quot;, 
    &amp;quot;state&amp;quot;: &amp;quot;file&amp;quot;, 
    &amp;quot;uid&amp;quot;: 3534
}

$ ansible build -m shell -a &amp;quot;ls /tmp/abcx.sh&amp;quot; -k                   
SSH password: 
10.16.28.18 | success | rc=0 &amp;gt;&amp;gt;
/tmp/abcx.sh

10.16.28.17 | success | rc=0 &amp;gt;&amp;gt;
/tmp/abcx.sh

10.16.29.179 | success | rc=0 &amp;gt;&amp;gt;
/tmp/abcx.sh

10.16.29.88 | success | rc=0 &amp;gt;&amp;gt;
/tmp/abcx.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;示例4-批量拷贝文件:f188025e536204472e8b7261593031f9&#34;&gt;示例4，批量拷贝文件：&lt;/h4&gt;

&lt;p&gt;TODO&lt;/p&gt;

&lt;h3 id=&#34;参考文献:f188025e536204472e8b7261593031f9&#34;&gt;参考文献&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ansible.com/&#34;&gt;官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://os.51cto.com/art/201409/451927_all.htm&#34; title=&#34;自动化运维工具之ansible&#34;&gt;自动化运维工具之ansible&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>